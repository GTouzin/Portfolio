{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB part IV : the final chapter\n",
    "\n",
    "In part 1, 2 and 3 of this series of post I cleaned, gathered and explored a data set of 5000 movies taken from IMDB by the Kaggle user deepMatrix. Now I will apply three different machine learning algorithm to create a model which will predict the profitability of a movie by looking at features that are available in pre-production. \n",
    "\n",
    "In the first part of this article, I will use the support machine vector algorithm, the XGBoost algorithm and a simple neural network to predict the revenue a movie will make at the American box-office. After using those algorithms in a regression context, I'll use them to label the movie either profitable or non-profitable. Using those algorithms in both context will be a good occasion to talk about the limitation of each and how the formulation of a problem can affect the performance of a model.\n",
    "\n",
    "As usual, the first thing I do is load the necessary library and the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(data.table)\n",
    "library(bit64)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "options(scipen=999)\n",
    "library(xgboost)\n",
    "library(psych)\n",
    "library(e1071)\n",
    "library(neuralnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies <- fread(\"movie_exploration.csv\",stringsAsFactors = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I choose the variables I could use in the model and classify them by type. Remember that some variables in the data set are the measure of phenomenons who should happen after the release of the movie, so they are useless for my model and I don't list them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_var<-names(movies[,c(\"duration\",\"director_facebook_likes\",\"actor_3_facebook_likes\",\"actor_1_facebook_likes\",\n",
    "                           \"cast_total_facebook_likes\",\"facenumber_in_poster\",\"actor_2_facebook_likes\",\"budget_2016\",\n",
    "                          \"profit\",\"gross_2016\",\"dir_mean_gross\",\"act_1_mean_gross\",\"act_2_mean_gross\",\"act_3_mean_gross\")])\n",
    "\n",
    "cath_var<-names(movies[,c(\"color\",\"language\",\"country\",\"content_rating\",\"title_year\",\"aspect_ratio\")])\n",
    "\n",
    "genre_var<-names(movies[,c(\"genres_Action\",\"genres_Adventure\",\"genres_Animation\",\"genres_Biography\",\"genres_Comedy\",\n",
    "                        \"genres_Crime\",\"genres_Documentary\",\"genres_Drama\",\"genres_Family\",\"genres_Fantasy\",\"genres_Film_Noir\",\n",
    "                        \"genres_Game_Show\",\"genres_History\",\"genres_Horror\",\"genres_Music\",\"genres_Musical\",\"genres_Mystery\",\n",
    "                        \"genres_News\",\"genres_Reality_TV\",\"genres_Romance\",\"genres_Sci_Fi\",\"genres_Short\",\"genres_Sport\",\n",
    "                        \"genres_Thriller\",\"genres_War\",\"genres_Western\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most functions in R can't handle the categorical variable, I coded them in dummy variable, like I did for the genre variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (f in cath_var) {\n",
    "    movies <- cbind(movies, dummy.code(movies[[f]]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created two sets of sample to train and test the different model. When needed, I will split the train data set to cross validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "row_sample<-sample(1:nrow(movies),0.8*nrow(movies),replace=FALSE)\n",
    "train<-movies[row_sample]\n",
    "test<-movies[!row_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "## SVM\n",
    "\n",
    "The first algorithm I'll use is the support vector machine. I choose this algorithm since it's pretty versatile, capable of doing linear and non-linear regression and it's quite fast. So it's a perfect algorithm to do a base model. \n",
    "\n",
    "Since the efficiency of the SVM algorithm decrease with the number of dimensions of our model, I started by making a simple model with only a handful of variables and then made another more complex to see how what is the optimal number of variable to include in the model. The variable used are the one who had a correlation coefficient of at least 0.2 with the \"gross_2016\" variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base.var<-names(movies[,c(\"duration\",\"director_facebook_likes\",\"actor_3_facebook_likes\",\"budget_2016\",\n",
    "                          \"dir_mean_gross\",\"act_1_mean_gross\",\"act_2_mean_gross\",\"act_3_mean_gross\", \"gross_2016\")])\n",
    "train.svm.base<-train[,base.var,with=FALSE]\n",
    "test.svm.base<-test[,base.var,with=FALSE]\n",
    "\n",
    "train.svm.base<-train.svm.base[complete.cases(train.svm.base)]\n",
    "test.svm.base<-test.svm.base[complete.cases(test.svm.base)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since the R function can scale the continuous variables, I can pass them directly as an argument without normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.svm.base <- svm(gross_2016~.,  scale = TRUE, data = train.svm.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultats.svm.base <- predict(object = model.svm.base, newdata = train.svm.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Named num [1:2818] 139158295 33673405 14807203 32264724 78546455 ...\n",
      " - attr(*, \"names\")= chr [1:2818] \"1\" \"2\" \"3\" \"4\" ...\n"
     ]
    }
   ],
   "source": [
    "str(resultats.svm.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the root mean square error to measure the difference between the real values and our model prediction. R doesn't provide a function to calculate the rmse so I have written my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse <- function(error)\n",
    "{\n",
    "    sqrt(mean(error^2,na.rm=TRUE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "71758341.3625101"
      ],
      "text/latex": [
       "71758341.3625101"
      ],
      "text/markdown": [
       "71758341.3625101"
      ],
      "text/plain": [
       "[1] 71758341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error <- train.svm.base$gross_2016 - resultats.svm.base\n",
    "rmse(error) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing a base model with the defaul parameter, I now must tune the model by choosing the best value of the parameter epsilon and the cost in the Lagrange transformation. Choosing a good value for those parameter will help the model fit the data without overfitting. I looked at the value of epsilon between 0 and 1 by increment of 0.1 and the cost value of 4 and 8. If needed, I'll look at other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter tuning of 'svm':\n",
      "\n",
      "- sampling method: 10-fold cross validation \n",
      "\n",
      "- best parameters:\n",
      " epsilon cost\n",
      "     0.3    4\n",
      "\n",
      "- best performance: 6047948505755821 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAhFBMVEUAAABNTU1NTf9RUf9W\nVv9bW/9fX/9kZP9oaGhpaf9ubv9ycv93d/98fHx8fP+AgP+Fhf+Kiv+MjIyPj/+Tk/+YmP+a\nmpqdnf+iov+mpv+np6erq/+wsP+ysrK0tP+5uf+9vb2+vv/Dw//Hx8fHx//MzP/Q0NDZ2dnh\n4eHp6enw8PD////XCCbkAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3da6OiyKGF\n4aLnnBOnZ5yZmMQkJCYmJm6F////DgVeULlVsYrruz70rnbbLva2nkYQwaSEkN4xYy8AIUsI\nkAgRBEiECAIkQgQBEiGCAIkQQYBEiCBAIkQQIBEiCJAIEQRIhAgCJEIEARIhggCJEEGARIgg\nQCJEECARIgiQCBEESIQIAiRCBAESIYIAiRBBgESIIEAiRBAgESIIkAgRBEiECAIkQgQBEiGC\nAIkQQYBEiCBAIkQQIBEiCJAIEQRIhAgCJEIEARIhggCJEEGARIggQCJEECARIsiaIZlbot25\n6W6HyJj9UMvUtgBxtrwXj8fI/plykch71vzrNc/E9fc62O+PCel1ATJJO48HAVLgrPnXW4Jk\nvmrvtfFbBejytgCx1/IAKXDW/Ou9T65z42u30afg+wLEPqukjYlEi0MqA6Qsl9soiSMTxdf7\nN68b+5LvOY/Pe/sa65x+fv+4MZtsnXaMzPa2ajvtsts3xWPZe5y32T+9rUmSOFvJbM/3vzw7\nH3lvqlr65JA9pNmdsuHX/T+Cfb5qrVqindcLQtI5QHqOrlHpZZ51kE332ys/e8t9vEtL388H\nxXeu8fNf3++b/81ugxV/yyXda+L0vfOeclNpAV5y/4d2EdLodgeTr3eqlujQtBlI+gdIab5G\nshPwPjWj2zeznJ7zePfYntqVvl/a0oqe3z1mUzl57Bh43KNYb9xrzPm985aXpjpI+7w8ycQc\n8yL7YOdCZ9USkcAB0mMbqZj9STFD8//Wk9K9sklqjtm3DzcB5e9ng+wfm80l/5Lm+weuz39r\np/Q5n/r2b9ldoksuYPPeWaSiqXrhbUWSP8ylMLp/rAE/logEzpp/yaaUS74iuMm4rUbO93vZ\nL/v8v/40/99///b9r5cvrw3PuyaPNVv+t83h+t5ZpKKpYuHt2mb/eP9rYx+nQNW8RCRQ1vxL\nLjk6v/z1tqGR3O+Vlv9+feh4/37pS3a3U7w1j7uW7vkysV87H7e9N1Us/KH4ZzdLB7tKy16H\nHhqWiITMmn/J9zm8jZPyX9+m78d8bPz+7ctpU/FQjZBM+bbqptfEd4H2Fd7V7nTYvrygBNKg\nWfMv+W2KRS9/rYDyWE9E1d9/frH7KDb746UVUlQxy2ub3pKcin1zdredRXS5vbID0hhZ8y/5\nbYrt7ls9r9+8DXZ1Wy5V03Zze6gqSNu3baSP4/xqmypy3t9XgdlW1v3fAWmErPmX/DbFsrkY\nfeVftuknlNp9aVXT9vaXyjXSsbzX7rWzSLe9dpvHbop86yrJV06NW20kZNb8S36fYo83eF52\ndt0Hj/dYi3eDGiFt8zd07G71T0jPmuN75y11TS/JuG2v+V6G4p3WvXlgBNIIWfMv+X2KnW/T\nN3755mOwLc/uZkhft7tGj0N2Snf5Kh/Z8NJ5T03Ta+47G7bPhT/VLxEJnDX/kj+mWH4Q3O78\n+s3nvc77qOIIuMppe8lWENH+cr0fnPDyT+zhdfeal85HqpvS9ztZRsfST5M0LBEJG37JhAgC\nJEIEARIhggCJEEGARIggQCJEECARIgiQCBEESIQIAiRCBAESIYIAiRBBgESIIEAiRBAgESII\nkAgRBEiECAIkQgQBEiGCAIkQQYBEiCBAIkQQIBEiCJAIEQRIhAgCJEIEARIhggCJEEGARIgg\nQCJEkP6Q7EVKojgRLAshs01vSNfisln5tbUJWWt6Q9rnF5uLb1eXI2Sd6Q3pcTW63otCyHzT\ne/5HN0hR70UhZL7pDelwe2l3ECwMIXNN/1dkR7u3ITq235GQ5aY/pEO+144VEll1ekM62pd2\nyd6wSiJrTm9IG2Pfi03M5vVhCXGI66wN/PgeGWD3t/nft/yPLD9MI52W9f23UMr/VeV3Vfnx\nNd/f8tNrfi7nl3J+Lee3Un5fyh8e+eM9f7rnz4/85Z6/3vO3In8v8o8i/yzyryL/LvKfIv91\nhvRft8wBUrH7O2nY/Q0kIAGpNbGxx9nF+U7wmgogAQlIrdnmL0K3DRVAAhKQ2pMf/d1UASQg\nAUlQASQgAUlQASQgAUlQEQzS2IDuARKQgCQIkIAEJEGABCQgCQIkIAFJECABCUiCAAlIQBIE\nSEAaAZLMEZCABKQFOQISkICkCJCABCRBgAQkIAkCJCABSREgAWmACiABCUiCCiC1SAKS65Ra\n4FmEOlQACUhiSP9xC5Dm4QhIQAKSIkAC0gAVQAISkAQVQAISkAQVQAISkAQVYRwBCUhAAhKQ\ngORasfhXdkACEpAUCQGpUhKQiikFJCABCUieFUACEpAEFUBqgdR9IwlIxZQCEpCABCTPCiAB\nCUiCCiABCUiCiiCQxrbzGiABKXwFkIAEJEEFkIAEJEEFkIAEJEFFCEczhKQ42A5IxZQCEpCA\nxFmEPCuABCQxpH+7BUhAAlLVlALSMvc1AAlIA1QASQbpd0DKpxSQgAQkIHlWAAlIQBJUAAlI\nQBJUACkUpHdJQAISkIDUfUoBCUhAApJnRQBIY8N5D5CAFL4CSEACkqACSENB+g4kR0hJHJko\nTvIHLR3f+ry163BoSBpHQAKSBNI1yvFE1zS9lCBt89HGZQgkTSYJ6ScgtUDamzj7MzZ7C2l3\nv/XLRJf0EpkvhyGQNAHSLCHd5r/9cjSH+62xOWd/nuwNnYdA0gRIs4QU3SBFFtLxfuvOZC/1\nilVU5+E8IY3N5jNAmiWkw+2l3cGKOO9NFOcP/1xPuQxDB0hAmiqk9Gj3NkR2XbQr9jVsUyCN\nmQCQxJ/sA1JVDrkeu3VkzMnuDbcv8IA0XjotNpCmBuloX9ol++fmUWL3aQNpvABp0mcRqjuj\n0MbYN1WT4h2h20M/d0E4DkMHSEBSQ/qXW7rs/i7dUuyJuz53ynUYAkkTIM0SUrE+Sezu7yhf\nOeU4Dvl7Q2f7sq/zEEia9IM0xGmEgFSR2NgD5mIrIv8jyd9fXc2RDWOrqQiQZgnpdqSc3eed\nFIfd5W8kbR63dh4CSRMgzRNScex2PrIHgm+Oj2Hp1i7DgSFJHAEJSDJIqgBJEyABKXgFkIAE\nJEEFkIAEJEEFkIAEJEEFkIAEJEGFGtLYaCoDJCCFrgASkIAkqAASkIAkqAASkIAkqAASkIAk\nqAASkIAkqAASkIAkqAASkIAkqFiDoxAfkQVS7ZQCEpCABCTPCiABaeSzCIWY12+LNEAFkKYA\n6eclQfqnW4AEJCBVTSkgAQlIQPKsABKQgCSo0EIaW0xNgASk0BVAAhKQBBVAAhKQBBVA8oPU\nQRKQgLQwSP0OtgOS25QCEpCABCTPCiABCUiCCiABCUiCilU4AhKQQlcACUhAElQACUhAElQA\nqRWS6h1ZIAEJSEDqPKWABCQgAcmzAkhAApKgAkjtkoDkNKWAtFhHQAJS6AogAYmzCAkqgAQk\nMaR/uAVIQAJS1ZQCEpCCQvoOJCABCUhdp9S6IQkcAQlIKZCABCQg+Ves4pVdiMO/gVQ3pYAE\npCEh1V6OAkjqAEkWIAEpbAWQgAQkQQWQgAQkQQWQgAQkQQWQgAQkQYUO0thWGjMnSL8ASRwg\nyQIkIIWtABKQgCSoAJInpCpJQEqBBCQgAcm/QuZo/pBqJQHJaUoBCUhAApJnBZCABCRBxTo2\nkYAEpMAVQAISp+MSVAAJSGJIf3cLkIAEpKopBaQFQ+r1RhKQnKYUkIAEJCB5VgCpHVLng+2A\nlAIJSEACkn+FCtLYUNoCJCAFrQASkIAkqAASkIAkqFjJJtIon+wDEpCABCQguVQACUhAan2A\n1uMCgQQkILU/wC1R/T2ABCQgdcvZfNVXiCCN7aQ1QAJSzyTRrqECSEACUqfsTNJQASQgAalL\nLiZuqgBSB0lAcshSITWukIAEJCB1ysXsGyuABCQgdUhszo0VQAISkDok+nyQl1O4aCCNzaRD\nRoD0LskH0q/zg7TIswhdTMO+71S2RhpbSYcAaShIf3PLPCAdzbG5AkhAAlJ7dubSXLGSTSQg\nAalXNo07v4HUA5L7J/uANF9IbZtyQAISkBQVQAISkAQVQAISkAQVEkhjI+kSIAEpZAWQgAQk\nQQWQgAQkQQWQgAQkQQWQgAQkQQWQgDRVSEkcmSgujijoNQSSMBOA9B1ILpCuUXEKrGs23ubD\nTeo3BJIwQJobpH1+koTYfjL1y0SX9BLZ02H5DOcCaWwjnQKkuUG6zX/7pfh46skc/IZDQerp\naDmQeh/+DSQhpNtnUu3pTXfGvr7LP1znMwSSMECaG6TD7aXd4WXl5DkMHSABaaqQ0qPd2xDZ\nT6YCaUIB0twgHfJ9bocUSJMKkGYG6Whf2iV7e7IEIE0ok4NUK2nmkPqk/EDFp7sT+45Q9BTh\nOQwdIAFJDemvbumy+7vY/XZ97olzG84E0thCOgZIM4NUrE8Su/v7kL8hdLav9XyGQFIGSDOD\nFBt7wFxsRczkyAYgAWmCkG5Hym3tcNNrCCRlgDQ3SMWx2/ko6TUEkjJAmh0kVYCkDJCAFLAC\nSEACkqBiNY6ABKSQFUACEpAEFUACEpAEFUACEpAEFUACEpAEFUDyhtQuCUhAAhKQgORQASQg\nAUlQ0RvS2D66p4ckIDlMKSABCUhA8qwAEpCAJKgAEpCAJKgAEpCAJKgAEpBGPotQiHn9tkgD\nVAAJSGJIf3HLYiD1cwQkIL1NKSAt2xGQgBSwAkhAApKgAkhAApKgAkhAApKgAkhAApKgAkhd\nIIk+2dcT0m9A8guQpAESkMJVAAlIQBJU9IQ0Ng6XAAlI4SqABCQgCSqABCQgCSpWBKmLJCAB\nya8CSEACkqBiPTvt9O/IAqlySgEJSEACkmfFil7ZAQlI4SqABCQgCSqABCQgCSqABCQgCSqA\nBCTOIiSoABKQxJD+7BYgrR5ShSQgAQlIQAKSd0UvSGPLcAyQgBSsAkgDQvoOJCABCUjdphSQ\ngAQkIHlW9HEEJCBVTCkgAQlIQPKsABKQgCSoABKQgCSoWJGjPp81B1L3KQUkIAEJSJ4VQAIS\nkAQVQBoP0k9AAtJSIdVIAlL3KQUkIAEJSJ4VQJJC8r7SGJACBkjiAAlIoSrW5Gj4z5oDCUhA\nAhKQulcACUicRUhQASQgiSH9yS1AGpuFe4AEpFAVQAISkAQVQAISkAQVa3I0F0i/AEkbIIkD\nJCCFqgASkIAkqAASkIAkqFgVJPUHkoBUNaWABCQgAcmzAkg9ILV+IAlIQAISkIDUvWJVjoAE\npFAVQAISkAQVQAoJqfuVxoAUMEBSB0hAClQBJCABSVABJCABSVABJCABSVABJCABSVCxKkdA\nAlKoCiABibMICSqANA1ItZ81nx+kP7oFSDMMkIAUqAJI3SQBqfOUAhKQgAQkzwogAQlIgop1\nQfLfSAJS5ykFpIk6+iZ8LCABKUwFkIAEJEEFkIAEJEEFkIAEJEHF9CF9+yaU5A2p6/m4gAQk\nIAEJSL4VQALSRCGVj2otH98aRyaKE5fhdCHpZnZ7gLRySFGaXkqQtvlo4zIEks03pSQgzQdS\nkbP5spB2979/meiSXiJ7a+chkH4oHAFptZCSyBI6msP9hticsz9P9obOQyD9sDBI34HkCGln\n7MbO0RyfN1zT2yqq8xBIPwBp3ZAuJrZfdua8N1E+vKmwX1yGoQMkIE0ZUrFCyr7k2aZA8s43\nqSQgzQrSxeyLxzSnbHMpti/wgOSXb5OG1PMs+kBqgVTsLbgnsfu0geQXIM0OUp+8PVZk3h76\ncZPrMHSABCQ1pD+4peHxS28fFQ9t7nvirs+dch2GQHpAUkkC0pwgPfZ6R/k+hxzHIX+1d7Z7\n8zoPgfRwBKQ1QtqZSzGILYsk32LiyAavqCF1kASkyUDaFDu/M0NRvgUVFzfe94R3HpYrHqqi\nyPEHa/6pgQSkyUJ6rkqSODKb42NYvDfbeVgFSbzlNBtIw722A9JkIKlyrzi/7CHcSCum7QhI\nQBLkUbEpO/qSVkwb0rdlQ6q7HAWQtKncRhJXAAlIq4IUqgJIQFoXpGO2bXTdiF/ZzQiSSBKQ\nVg7pXBw7lGWl20hAApJvyhVbc0ovZpOeineauuayN2Z/baiYNKRvY0CSniESSFODZFdI+ccF\nnfY6FDvOo6S+AkhAWh2knT3WyAlSFF3SZFccWlFdMR9IGklAWjmkrbmc7Rm+nF7anXJCiak/\nqghIQFoXpPxF2sGukM619//I/n70bH3FlCF9AxKQFHnd/R3lq5fNyeEBNiY9RGZfv4kEJCCt\nDZLXA5j89CsNx4vPCZJEEpCA5PEA9oNNyf55msrPewAJSCuDdLJnBN+5vLLLINltpGvDAeNe\nkBQTukuABCRJXiq25nmSvM4PUHkWlZcPZUwY0rsjIM0DUs8zBwVIueJoovxEDtHzLMjt2bWe\njmh1kMTHCLVB6n4W/TpIvw4O6U2SM6Tfu2VgSJvbnuyLywf7irOoXBvWYrOCNNAqCUhLhvRY\nq7isCrOto8TubKjfsAISkNYF6blGcjn5yaFtswpIQFoXJK9tpOz+2/sJVWoqpgvp0xGQgOSV\n3nvtOlTMCpJCEpBWDik97ZzfR+pQASQgrQxSmAogAQlIgorJQqpyND1In5KANHFISWx310Vx\nw6HcPhXzgiSQBKR1Q7oW59Q3Jmo4A4NHBZCAtCpI2+JjRUn8du2lvhVAAtKqIHkd2dChYqqO\ngAQkWcoV0e1SMclKIFU7AhKQPFKuiM3Wnhnya9twSiCfiplB6i8JSOuGNKEjGwRM2gMkIMlS\ncWTD1ulIuw4VQALSyiCFqQASkIAkqJgopDpH/SUBCUghKlYHqV0SkIDkXgEkIAFJUAEkIAFJ\nUDFNSPWOxttIAlLHKTXt03GFqgASkMSQfnMLkAJmxpCazxAJJCABCUidphSQJuMISEBSZrWQ\nmhz1lgQkIAWoANKgkL4DCUhAAlKXKQUkIAEJSJ4VM4TUUxKQgBSgYoqQWhwBCUiOizRABZCA\nBCRBBZC6QvI7ZzGQgDRZSP0kAQlIASomCKnVEZCA5LZIA1QACUhAElQACUhAElSsD9KwH5EF\nEpBGctQBUuBVEpCA5FwxPUgdHAEJSE6LNEAFkIAEJEEFkIAEJEHFPCH1kjQhSDWS5g2JswgB\nCUgCSL+6BUhh0skRkIDkskgDVAAJSEASVMwUUh9JQAKSvgJIQAKSoGJqkDo6AhKQHBZpgAog\nAQlIggoghYXkdYZIIGkDpCCSgAQkfcXEHE0C0ujXdQGSNiuE1NkRkIDUfZEGqAASkIAkqJgt\nJH9JQAKSvmKFkHz3NgCp25QCEpCABCTPimlBcnAEJCB1XqQBKuYLKeBGEpCA5FoBpAlCepEE\npN4BEpCAJMjqIDk5AhKQui7SABVAAhKQBBUzhuQtCUicRUheASQgiSH94hYg6QMkIIXIBCEp\n2XzE0dHQkDpe1wVIQJoZJF9JQAKSvAJIPSE5nrQBSEACEpC6TCkgAQlIQPKsmBAkZ0e+koAE\nJHkFkIAEJEEFkIAEJEHFGiG1SgISkFwrpgPJwxGQgNRpkQaomDekQK/tgDQFSC9HtcaRieIk\n9RsCCUhAMlE23uajTeo3BBKQVgypyNl8pemXiS7pJfIdAglIa4eURLvsz9icsz9P5uA3nB4k\nLZ2XeDnylASk2UDamST/85r9eTE7vyGQlgfpO5BcIF1MnD9mcSf7xXMYOkAC0pQhFSskIDlk\nSpCUH5EFUg9IF7MvHhNInQMkIH2k2FsAJId4OvKTBKQpnUWo4YxCkXn5ar/vOQwdIAFJDeln\ntzQ8fr7rzabY/XZ97olzGwIJSKuGdDTHYnDIX+Kd7S48nyGQgLRqSDtzKQaLO7JBzecRb0de\nkoA0D0ibYud3PrLZeg6BBKRVQ3quSpL8MG7fIZCAtGpIqgAJSEASBEiBJAEJSOqK+TsKsUoC\nEpAcK4AEJCAJKoAEJCAJKoAEJCAJKhYAKcDeBiABybFiEpD6OQISkFoWaYAKIHWH1FHSj42S\n+kD6DUheARKQgCQIkEJJAhKQxBVTgNTXEZCA1LxIA1QACUhAElQACUhAElQsApKzJCABSVwB\nJCCNfBahEPP6bZEGqFiEIyBNCdJPbgGSKkACUtgACUhAEgRIoSQBCUjiCiABCUiCivEhKRyp\nX9sBCUiOFUACEpAEFQuBNMxrOyB1mVJAApIEkstFZIEEpEk5AhKQGhZpgAogAQlIgoqlQHKU\nBCQgaSuABCQgCSqABCQgCSqW4ghIQKpfpAEqgAQkIAkqFgPJTRKQgKStABKQgCSoABKQgCSo\nGBmSzhGQgFS7SANULAeSkyQgAUlbAaRRIf20QEicRQhIY0L6eSmQvrsFSBNzBCQg1S3SABUL\ngqSU5AKp5ZN9QAISkIAEpG4VQAISkAQVQHKA5HXSBiABaV6OgASkmkUaoGJJkFwkAQlI0gog\nDQyp06ENQJIGSEACkiBAAhKQBFk6JLUjF0lAApLLI7QdFggkIAGpNRcgAQlICki7tgogAQlI\nbTmaQ1vFiJD0jhwkAQlI3XM0x7YKIAEJSG3ZmfPeRHFTBZBcJAGpPcuElGfbUAEkIAGp9QHM\nKU2TuOEFHpCABKSOScymvmI8SCEcdZcEJCC5P455+2spozkC0lIhLfcsQg3LulpIyo/INkPy\nObHdrzWSZgHpR7fMAVJkkuzPa8PbskACEpBaE5s4tTsbzvUVS4Okem0HJCA9k0T5i9CGN5LG\ngxTIEZCA9LlIvR8hiSOzaTq6AUhAApKiAkhAApKgYnGQukoCEpCUFWNBCuYISED6WKQBKoAE\nJCAJKoAEJCAJKoAEJCAJKpYHqaMkIaR3SUAC0lCQAjoaH1L/i8gCSZopQdI6AhKQgAQkIDVN\nKSAtBFI3SUACkrICSEACkqBiHEhBHQWEpL9AEpCABCQgVU0pIC0FkkISkIDkVAEkIAFJUDEK\npMCOgDQqpOWeRaipAkhAEkN6/220BEhAAlLVlALSYiB1kgQkIAkrgAQkIAkqxoAU3BGQgPSy\nSANUjOBoFpDCnfwbSECaDaQukoAEJGEFkIAEJEEFkIAEJEHFCJAGcDR3SHUXSAKSV4AUUhKQ\ngCSsABKQgCSoABKQgCSoGB7SII6AtARIl70x+2v+oKUDxePIRHHiMgQSkNYM6ZzjiTISlxKk\nbT7auAyBFFISkKYOKYouabKzF5y8PC+D/GWyWy+R+XIYAikkJK+D7YDUPqVUkE75NVsTE6Xp\n0RzutxZXRD7ZGzoPgQSkFUPam8t9eDSP67fujN1oyldRnYeLhDSQIyDNHlK2aXOIzN7uNdiZ\n895E+UXFbyrsF5dh6HSEpHM0GKS+G0lAGhuSMbt8Z0NqIeXZpkACUrUkIDVAsjsb9nZjx5hT\ntrUU2xd4QFowpOYLJAHJF5LdRroWO7JtEjsEEpBWAqlPXh+o/OU+jIzXMHQGhzSYIyCNBanm\nd1SX2sffVUIq9sRdnzvlOgyBFFQSkKYN6ZC/C3S1uxgik6Q3HMWtZ/seU+chkIC0YkjZ1lFi\ndzac7Durcb6z4Tz3IxuABKTOU0oFKVuh3Pd5J1E+zN9I2jxu7TxcIKQBHQFp7pDS8/b2Lmy2\nNorM5vgYlm7tMgQSkFYNSRUgTQ5St3dkf2yUBCQgAQlIrVMKSEACEpA8K4aFNKQjIAHpvkgD\nVCx3hQQkIN0XaYAKIAEJSIIKIAEJSIKKFUNqlgQkILlUDAppUEeT/WQfkIAEJCC1TikgAQlI\nQPKsABKQgCSoGBLSsI6ABKT7Ig1QASQgAUlQASQgAUlQAaRxIXW4iOzcIPU5c1CYACmsJCAF\ngVT9i6sNkIAEpKopBaTAjoAEJCABCUgdpxSQgAQkIHlWAAlIQBJUDAhpaEdAAtJtkQaoABKQ\ngCSoAJICktMZIoEEJCABqXVKAWltkHw+aw6k1ikFJCABCUieFUACEpAEFUACEpAEFUACEpAE\nFcNBGtwRkIB0W6QBKoAEJCAJKgZzBCQgAQlIQOo8pYAEpHZIPif/BhKQgAQk1ykFJCABSQCJ\nswgtDVK/o1aB5Ampw5QqB0hAApLnlALSrByN98k+IAEJSEACknsFkIAEJEEFkIAEJEEFkIAE\nJEHFqiHpjhECktOUAhKQgCSYUquEpHEEpBpJQAoxr98WaYAKIAEJSIKKoSCN4QhIQCoWaYAK\nIAEJSIIKIAEJSIIKIIWH5HFZcyApAyQgAUkQIAEJSIIACUhAEgRIs4Hkf2gDkELM67dFGqAC\nSEACkqBiIEijOAISkIpFGqACSEDiLEKCikVDCnH2EyC1TSnHqbEWSJ5y3gIkINUESC4BEpBq\nAiSXAAlINQGSS4AEpJoAySUThdQoCUhA6l4BJCABSVAxDKSRHAEJSPkiDVABJCABSVABJEdI\n6vNxASnEvH5bpAEqgAQkIAkqgAQkIAkqgOQqCUgtU8pxbgDJIUACUl2A5BAgAakuK4HkB+c9\nQAJSXYDUPWM5AhKQ8kUaoAJIQAKSoAJIQAKSoAJIQAKSoAJIQAKSoAJIQOIsQoKKZUMa7iOy\nQHpMKcenCEhAAlLVlHJ8ioC0BEiyDyQB6TGlHJ8iIM3AEZCAlAJJECABCUiCAAlIQBIESECa\nBCSFIyABqSFAAhKQqqaU41MEJCABqWpKOT5FQAISkKqmlONTBCQgAalqSjk+RbOB9NX0MENA\nCiKkY4A0Z0iXvTH7az6MIxPFiedQAimJgASkWUI65weHR5bENh9uUr+hBNKu8Th1IAFpspCi\n6JImOxPbV1XZ8BKZL7+hAtKp+QMfQALSVCGdLKE0MVH2Cs2c8xsOfkMBpKvZAglIs4S0N5f7\ncGfsltLF7PyGAkhbcwUSkGYJKdu0OURmbzeRbnPYfvEc9szBnJofBkhAmiokY3b5zoZ0fEj5\n+g1IQJopJLuzYW83dsaGtLG7DoEEpJlCsttIV7sje2RI+3ynxcfDOJ/mhaw6jrNO1lViEPUe\n9kqH38UAx2eMVMaPNseycnZPBsXut+tzT5zbEGARadQAAAViSURBVEizaeNH0+eQv6C6mu19\neLZvLPkMNT9C8zaSpKJjmG1zbBsNUrZ1lNidDadJHNkApOWVLflHK+eQv5ra2uGm1xBIs2nj\nRwuR89ZEcT5K8sO4fYcD/AgLfkr40WZYFiZAmk0bP9qUA6TZtPGjTTlAmk0bP9qUA6TZtPGj\nTTlAmk0bP9qUA6TZtPGjTTkL+BEIGT9AIkQQIBEiCJAIEQRIhAgCJEIEARIhggCJEEGARIgg\nQCJEECARIgiQCBEESIQIAiRCBAESIYIAiRBBQkEqXfW55oaQZcdNuLLKn6Txsu7SstJVuMO3\nJSGftexpev2thS0LnEAToHTV55obQpbF+Q1RmOek6idpvqy7suw85I92jYq2QG7frhcZcoqE\nT5gJUDo3cs0NIcsu+bUMj2YfoKz6J2m+rLuy7HkV7gHa9nlPHOYX+X7C7JBTZICEmQClqz7X\n3BCyrHStjgHa0tbLugvLSlfhHqBNd33UihzfruEdcooMkDAToHTV55obQpbdEub5r2hru6y7\nsKx0Fe4B2u4X0QrCNvsv4eW3FnKKDJAwE+Djv7KQ/7fVPHZSXCxggLa2y7oLy0pX4R6g7XB7\naRdkJXF5e8qCrv7CZ7mQjvlLhQHaWi/rLiwrXYV7gLb0aPc2RMcgbSmQOjzq+JCuUZjXCB9t\n7Zd1F5aVrsI9QNvt6kHBtlqA1Pqoo0NKoiAv7KpebbVe1l1YVroK9wBtR/vSLmMbapUEpLZ8\nXOpZde3nTmU221DvR7y31VzWPUxZ2Nn20bYxdmMsCfbezsuPEXKKDJCQe5uu73vtrgH32r08\n9nWzDfXm/3tbh6tR68rC7tn/aAu9kqjYaxdmigyQML+j0lWfa24IWZaNA72uq2gLCqnm93gN\n8/N9tBUriUDvWqVvkEJOkQGyxCMbAs2zmrY8Qx3ZULoK9wBtsbGHvsXB5jZHNrSmdNXn4rdV\nuiF42T7gOqLiR3sdBS47BPw9frZtQ7Y9f2vhp0j4BJoApas+F7+l0g3By0K+2Kr40V5Hocue\nV+Eeoi3gs5a+Qwo5RcJnpvtICJlWgESIIEAiRBAgESIIkAgRBEiECAIkQgQBEiGCAIkQQYBE\niCBAIkQQIBEiCJAIEQRIhAgCJEIEARIhggCJEEGARIggQCJEECARIgiQCBEESIQIAiRCBAES\nIYIAiRBBgESIIEAiRBAgESIIkAgRBEiECAIkQgQBEiGCAIkQQYA0Ruwl6oJdK5yMEZ7NMQKk\nxYVnc6wAaVHh2RwrQFpUeDbD5Lgx0dEOMi/x/WLd560x23NafmmX3W9zu991Z6LDWMtLegZI\nQbIzNtvUAjnch8f8RnMsQdqW7hfZIZJmGiCFyNlskzTZmnMO5JJeInNK08hc0vRkNk9Ip+c3\njf0nR/tNMscAKUR2Jsn+TMzOArGv5c7Poc0d0u72za3961fKhtN8wxMXIuaeBw37JTZmd7nc\n//b2zWIIpLmGJy5EqiGlB7sZFF2BtMDwxIVIyUMZUvYqLt6Ut5GAtJjwxIXI7rE1dNv2OZv9\n84bPbaQdkOYenrgQyffGpccCSLFjLhOzsXvn6vfa2X8IpLmGJy5IiveHis2hfJyRytjk+ap5\nHylNgTTf8MSFyXFjzD5zZGnsbgcvFEc23Pdy345siB5HNjz/JPMLT1zgQGMd4WkOHCCtIzzN\ngQOkdYSnOXCAtI7wNBMiCJAIEQRIhAgCJEIEARIhggCJEEGARIggQCJEECARIgiQCBEESIQI\nAiRCBAESIYIAiRBBgESIIEAiRBAgESIIkAgRBEiECAIkQgQBEiGCAIkQQYBEiCBAIkQQIBEi\nCJAIEQRIhAjy/7L73XOyqinRAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Performance of `svm'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "svm.base.tune <- tune(svm, gross_2016~., data = train.svm.base,\n",
    "              ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:3))\n",
    ")\n",
    "options(warn = 1)\n",
    "print(svm.base.tune)\n",
    "plot(svm.base.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The darker area on this plot is the region where the to optimal value of epsilon and cost is located. Since this region seems to be located between e=0.1, e=0.5 and cost<4, I search deeper in this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter tuning of 'svm':\n",
      "\n",
      "- sampling method: 10-fold cross validation \n",
      "\n",
      "- best parameters:\n",
      " epsilon cost\n",
      "    0.26    2\n",
      "\n",
      "- best performance: 6023072951120205 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAYFBMVEUAAABNTU1NTf9VVf9e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\nQgQCJEIEAiRCBAIkQgQCJEIE8v/Cl4Ef/43z2QAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Performance of `svm'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "svm.base.tune2 <- tune(svm, gross_2016~., data = train.svm.base,\n",
    "              ranges = list(epsilon = seq(0.1,0.5,0.02), cost = 2^(0:2))\n",
    ")\n",
    "options(warn = 1)\n",
    "print(svm.base.tune2)\n",
    "plot(svm.base.tune2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the region is more define. Let focus on the region e=0.2, e=0.3, cost=1 and cost=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter tuning of 'svm':\n",
      "\n",
      "- sampling method: 10-fold cross validation \n",
      "\n",
      "- best parameters:\n",
      " epsilon cost\n",
      "    0.25    2\n",
      "\n",
      "- best performance: 6024713655296222 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAgVBMVEUAAABNTU1NTf9RUf9W\nVv9bW/9gYP9lZf9oaGhqav9vb/90dP95ef98fHx+fv+Cgv+Hh/+MjIyMjP+Rkf+Wlv+ampqb\nm/+goP+lpf+np6eqqv+vr/+ysrKzs/+4uP+9vb29vf/Cwv/Hx8fHx//MzP/Q0NDZ2dnh4eHp\n6enw8PD///99tKrNAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3dbWPyuNG3cfl6\n6E2vLt2ye7ItLS1tWgLm+3/AG9tg/OyRNKORrP/xYk+HkAzY+i2BEDAPhJB3RvsCILSFAAkh\nhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYA\nCSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkh\nhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhgAJIYYACSGGAAkhhnKGZF4V\nh+vS2c6FMcdQl2ntApyel/fm8D2eX8Z5kdCwnHev+XSaP9e5+rwmpP4FeEo6OHwTQBIu593b\ngWS+Z8+1c7sJ4GtwAU5OlweQhMt5974X13XxZzf1JTi8ACeXm6SdKZguDpoMkJ7dXlvlqTDF\n6f7+5H1X/cj3WcfXY/Uz1vUx/vxlZ3bP27RLYfavm7avw/P0XfO9qnNc988vfd2SlKfnjcz+\n+v7gM7NtOGnq0pfn57c0h6/n5vf7fwTH+qZ16hIdnH4gROQA6bN1Lzo/5lUOnsv99ZNfdcp7\n+/DofL7eaD5zP32++n3e+qPqPljzUS3pPeb0GM58153UuQC93l9YXYRH8TqDqW93pi7Reelu\nIPIPkB71LVK1AN9Ls3h98tnXZx0f2vtTh87nO/e0is9nL8+lXLYPDHzuidW3G+8x5jqc+ao3\naQ7SsR5ePsVc6kHVN7s2OqcuERIOkNr7SM3qL5sVWv9vveyc67lIzeX56fNLQPfzz43nF5vd\nrf7nUT8+cP98bbWkr/XSrz56nqW41QJ2w5lNE5OmL3w1oqy/za0xemxvAUeXCAmX8042nW71\nDcFLxutm5Po+V/XPsf5f/6P+v/9x8Pnv3j/9CZ+zlu0tW/3R7nwfzmyamDRx4atbm2P7+69d\n9X0aVMuXCAmV807uOLr2Pnzd0Sjf53p0P763Ooaf7/zzPNvXaW/as3bO2VvY/ZntacNJExf+\n/Pph8fr+6Ovx/Dn0vHCJkGQ57+T3Gt6fyu6Hg+U7Wo+Ln3/987Wb+FaLkEz3tOlJ/U5vgdVP\nePfqQYd97wdKQApazjt5sMSK3ocTUNrbiWL6859/qscodsfLbRVSMbHKZycNKr+ax+aqh+0q\nRLfXT3aApFHOO3mwxA7vez39T742DnP3XKaW7e71raYg7Qf3kUbP85udNNH1+L4JfN7Len8d\nICmU804eLLHnWiy+63/2jzGU2cfSppbt64PJW6Teo3b9mU20R+127cMU9b2rsr5xWrzXhiTL\neScPl1j7C57eg13vjfZ3rM1vgxYh7etf6FQPq48hfcZchjNfzU3q9eS2v9ePMjS/aT2aFiMg\nKZTzTh4usetr+Z56n2w39t3VvQzp+3XWon3KTucs391nNvRmvpuZ1O/9YMP+c+G/5i8REi7n\nnTxaYvWT4A7X/ic/57oei4lnwE0u29vzBqI43u7vJyf0vqR6et17TG9m2/Skx/BMFaNL59qU\nC5cIyYadjBBDgIQQQ4CEEEOAhBBDgIQQQ4CEEEOAhBBDgIQQQ4CEEEOAhBBDgIQQQ4CEEEOA\nhBBDgIQQQ4CEEEOAhBBDgIQQQ4CEEEOAhBBDgIQQQ4CEEEOAhBBDgIQQQ4CEEEOAhBBDgIQQ\nQ4CEEEOAhBBDgIQQQ4CEEENOkL57X3UqTHEqeS4OQmnmAqksul/VvCvWjusCIZRiLpAO3beu\n+q7eEfVWdN+6EaHscoD01XsPuFP9hsFf5sx2kRBKL3tId7PvQjqY+6N6/+4D32VCKLnsIe3N\nvQupfX9UrkuEUIJZr/+z+XoAEkL9bNf/rXmb7s43ACSErCHtihKQEBpmuf6P9WN0XTXFJCSD\nkEW2q1b4+ztkOWJ80ZpH7e4Lj9qZv6C6P0+nfbHcm7lC9llD+o9dKUA617dRV3Oa/xrt460e\ndT1pX056bIRyhfT6IqtnNpiUVghzritL+3LPx+mnLXNIzT+7+gZqv3DuuFeGTGxrTPuKfGK7\nSuMA6VlZP/t76dyxrQjZxFbbBq/Su1whWY7QXwlBEl9uCvswyHUCJOIItWVAa+0o+38H7uT3\nSeDrBEikEcEXAb2gy4W1Te0UQCKNCLcErAq/Xtjbyi4BJNKI0X7jPv7prBiBtrBHAIk0YmLP\nMR395FaMVInvEEAijZjcd1wuUlszgqW5P357BkikEXO7kB9K7ItGvrT2xm+vAIk0Yn5HSsKJ\nb9kEK4md8VsnQCKNWNqdMCRU1Pvit0GARBqxvFOBSK4Id8XQECDRR6ztWyDKpElEgEQeQdjF\nQLT1ZhEBEnkEaUfD0HZbRARI5BHE3Q1CG2zVECDRR5D3OgRtKhoiQCKPsNj3ELSR6IgAiTzC\n7hBAUOrZIXKClPzLcTmNsD0QIJRs9obcIP3brkwhTVHiP+YajVaQ9gXiy5EQIFmMcDkuWxc0\nTvsiuuYlCJBsRmgfas2c1pX2habFIQiQbEZoH3GVmJaY9tWYiumqdQIk0gjtAx84/nXWpH29\n/ix31QCJNEL78IdKapl12+ZVAyTSCKWDHy7hZTZqc1cNkEgjAh53l8KsFe42tVcAiTRC+ph7\nFHS58LeVfQJIpBFR3E8ep7BgJNrCHgEk0gju482Q2pIRKvH9AUikEa+9xQGAIdUVI1q6uwOQ\nSCM+O4zZRJqrRrQ0dwYgkUb09pkYkoTWjXTJ7QpAIo0Y7LUQamJfOfIltSMAiTRivONgKEyp\n7AdAIo2Y2nVAhOp+VAESacTMLgSizPvRBkikEfO7Eogy7Uc/QCKNWNqjMJRbPyYCJNKIlT0L\nQ7k0ZQiQ6CPW9zAMbb1ZQ26Q8nw5LsqOBqHNtmzIDdK/7MoI0m/2lkSPPuKIYAiQ6CPI+33z\nhIYLSPvyCEY1BEj0ETb7f6OG1laS9uVjzcoQINFHWB6HTRmyXVLal9cze0OARB9hfTi2QMhx\nSaUpyvfKAhJphMuhSdiQ76oapH11FmK7joBEGqF9vEPFtq6m0756bfxXDZBII7QPvHj8K2u2\nbV5LQCKNUDz4pARXiEyb2zuARBoR9LhbFmKZyLSlHQNIpBHCh9y5oGtFpo3sFkAijZA42r4p\nrBax0t8ngEQawXWgudJbMIIlvUMUId2Oxhzvrw8unTN+v7ZPhSlO5epmbpC0l4xsqe4NPUjX\n+q8siobErfP3FmXRbO/rM+xWN3OCpL1cApXgrtCDVBS3R3kwp2r7VnQgHZrtb/M8w/MT32ub\nuUDSXiqhS2s/qEH6qgmVpnhUP9ftPxy+Xn8NeDLX+qPz2mYOkLSXiVrJ7AQ1SEdz+3zT06Pl\ncH+jOpjq/tPNHNY2Q0D6ofgLee0lgiipQXretTkX5ljfRbo9PpD25t5sv06p/lndlM40OwuI\n0FxqkIw51A82tB82/57N1yNaSD+CWlJcFcg6RUjVgw3H6s5O82H9T/0zW8yQfoSxpLUckGuK\nkKr7SPfmgeyWw656ODxySFVAhPqJvxzX3EtzDRg0/x7rB+Ka7eJzhtVN6UaQfghZCn78EVPW\nkP5p1+z3P0xB6pprHpS7fx6fm9tUgvSD2VLY4464+rVJDdK5vvG5m/3r+44gNWe4Vr9uWt7U\ng/SDy1LA446Y+rWfGqTnvaOyerDh6/V9O2eM8JkNi7s0K0OD9fOr9uUJ3nAHaEN63qBU7d/f\ndwTpsfucYXFTHdIPV0shjjtbMwsoG1ErV18P0uO6N8Wp/b5jSGX95O71zRgg/bC1JH7c+VoT\ntHFRxGutCImrSCD9IFuSPfB82QralijLKwtIpBH0/b8JQ76EUhbleB0BiTTC6lAkjIjVzzjt\nq7eQ71UDJNII28OSnCEOJsS0r2ovtmsFSKQRDocoNCK2JRGkUHsl2M4CJNII5eO+Gv/CCNGW\ndhMgkUYEP+QWCa6OEG1kDwESaUSAo+1UiCUSovR3DiCRRogcaN+CLpQAJb1bAIk0gukY86Wz\nWgKU6h4BJNIIRgL+KS+ZACW4MwCJNEIMhXXaCyZcae0GQCKNCKRkJe3FolAyewCQSCNU3CSy\nhFAVIJFGQBFaDpBII4AILQdIpBFAhJYTfzkukYXdv0gBRkARWs4a0j/sihFSWb3D2a1zwqr5\n4JC0lwWyLUdIRc3mI+kWFyTtJYFcyhDSyRyr/xzaE26d7ZkRv4Z6zr/2ekCOZQipMNV7yXRu\ngC7vV/KfH/HaW0D0Sz/tixNPGUJ6fVXRbl7MZe3MnT2WJ6JfltO+ePrlCunUwXMw12PnJfam\nRgz2Wj6IVgAB1Ls8IX0Z03FzML0XfZ0aMbHnNo7IUlD2oPKEdDkUnftFpnoB8vK08APeFKSq\nDSLyA5QLqPE1zRPSo3orpoGb8v2eZ1MjFvbpRhDxAtoWKMo1zBZS2Xm04fV9zODDTit7OmFF\nsoAGaV9ZSo5XLVtI43f6W/iN7BqkKm1ErCteNLFd4JH3lcoQUvN7pPvnJ7n3CfO/lqVAqlK7\nJWJY3oGT2xf0OK9PhpDqZzaUh899pFP1EF55qt8AcGaExdEJ/+Mc53oInOBeCby3MoT0eq5d\n/Wh3/eNc2Zyw8IskG0hVQGST4O4Jt5tyhPQ4FWbX3B4194vKzwkzIxyOXYAHFuSXR8AS3z1Z\nQrIfwX+UfQu6SoKV7n4BJNII/wPMmtZqCVSK+wOQSCMEMLimvWJCldiOACTSiABASGkvl+Al\nswMAiTRCA80o7bWCFgIk0ghtQ0AUe4BEGgFFaDm8HBdpBBCh5awh/d0uQIKiLAIk0gggQssB\nEmkEFKHlAIk0AojQcoBEGgFFaDlAIo2Aoro/jdO+SLEESKQReSOa8ANRgwCJNCJLRSQ/ENUE\nSKQROSly9JO5KEAijcgAEZufPEUBEmlEva82qUjQT1aiAIk04rPDkkQUVMtaYa96qACJNGK4\n2yJUpO3DLpFdoBkgkUZM7jso8kxkV/jmeF0AiTRiYcerI0pU0TuZfRJ83wESacTa8cBNkV8i\n+ybo3gIk0gjacYIir5LePYBEGmFx+IDIq1T3CyCRRlgfTyjyKcH9AUikERIaHNNeMcFKa0cA\nEmlECCGUtJdL8JLZAXgVIdIIDTSjtNcKWsga0t/sAiQgyiJAIo2AIrQcIJFGABFaDpBII6AI\nLQdIpBFAhJYDJNIIKELLARJpBBCh5QCJNAKK6n4epn2B4gmQSCPyVjTyA1CjAIk0IktF634A\nqg2QSCNyUuTgB6AAiTYiA0UcfjIGBUikEdtVJOInQ1CKkG5HY4731weX9xkvO1OcynrzVJA2\nE4YU6iiH0bJeqOurkB6ka/1XFkVD4vb+e4vT59R9vbl7rG2mCon5SGojocd8xeNID1JR3B7l\nwZyq7VvxgnQzx7K6eTo+Ht/meYbnJ77XNpOExHwYtW3Yx7wD1FOD9FUTKk3xqODsXxwOzT/V\nRydzrc92XttMDxLzMdQ24RHznlBMDdLR3D7f9PToc6g+Opjq/tPNHNY2E4PEfAC1KTDEvEd0\nUoP0vGtzLuof5J4YHn1Ipdm3p1T/rG5KxwaJ+ehpE+CMeddw7jjKd1SDZMyhflih/bDzuUv1\nQ1tUkNr9BUWipbKDxsMUIVUPNhyrOzvNh59P3YvDI1ZIbVAkV4q7RRFSdR/p3jyQ3eNQFvvO\nKbFCaoMimRLbF+IvxzX30lwDBp1P7htbxecMq5vSLUFqgyKBktkB1pD+atfs9z/MQLrv9vfX\nGap/75/H5+Y2Y4HUBkUZpgbpXP8W6G72r+/7OuP1fcLrDNfq103Lm9FBkkp7raCF1CA97x2V\n1YMNX6/va16nvh3F9cwGbUNQFHtqkJ43KFVvNy8Ox87dqd3nDIubGUDSXiVoNT1Ij+veFKf2\n+77vMn0glfWTu+uTFze3Dkl7iSBKipC42jQk7fWBiAESaQQUoeUAiTQCitBygEQaAUVVfxyl\nfYniCZBIIzJGNNYzkfaF1A+QSCNyY0TSA1CdAIk0IgtFrnoA6mdAIo7YriJGPVmDAiTSiK0o\nkmWTMyhAIo1IU5EWm9mkrmgEARJpRAKKtJHQ47rGUQVIpBFgxB3XFY8lQCKNgCKZuPaAfoBE\nGgFFgnHtCdUAiTQCisTj2iVKARJpBBSFiWvXhA+QSCOgKGSqu8hxmPjLcYks7P5FCjAiMka8\n6zbO9PeJ1XhrSH+xC5CgyKcodgIgsY2AIvTHRVGARBoRhyIwiiVAchwBRWgyQLIbsbC+oQg9\nAyTSCC4PULTVAIk0AorQcoBEGgFFaDlAIo2AIrQcIJFGQFHVT8O0L1BEARJpRMaKRnrGaV/E\nGAIk0ojcFBH0wFOvHCGVR2OOt+4p9fvDlAsjsmDkpAeemnKEVNRPS+9I2tcn7BZGbFcRk57s\nPWUI6WSO1X8O7Qmdt9OcG7EpRmJ2cvaUIaTCVD/Edf5S6lS/q/OXOc+PSFxRUDp5esoQ0uur\ninbzYO7P/946t1GjMyfHSBvOdOxXM55yhXQyl883MN1/JkckoEgbiUU8Vziu8oT0Zczp85Eq\nJKbjqG3DIaZrHkl5Qrocis49IkVIPAdRm4RPPHtAvzwhPTt+frbTgsRzBLUlsMSzKzTLFlL5\nebShmITUey2kWBlpA+CNZZcole/LcX0uWvOo3T3ko3Ysx0573QvFsm+CZw3pz3ZFCKn5PdL9\n80yGc/17pGv38YfhiPgYaS936Tj2UcgyhFQ/s6E8fO4jhX1mA8dR017lwVLYFY6HJENIr+fa\n7euvrb949zlhZgQU5RYgEToVZtfcHjWQyvrZ30sjomGkvb4yC5CYR8ShCIx0AiS2ETEw0l5O\nuQdIDCOgCDUBktcIXUbaiwcNAyTHEVCExgGS9QgoQnMBksUIUS1QtIEAiTRCTksyiv4wlfaF\niidAIo3IUtEknem0L6p+gEQakYsiCzsA1QuQSCO2y8iXDkA1ARJpxKYYydjJHBQgkUYkzigg\nnVxBARJpRHKKtOVMx3sdowqQSCMSYKSNxCL/KxtfgEQaAUb8+V/pmAIk0oi4GWmT8IlhDUcR\nIJFGQJFsDCtZuXxfjstqRKyMtAHwxrGgtbKG9JtdgARGlnEs6/ABEmlEhIy017twLKs7YIBE\nGgFFOrGs8SABEmlEVIy0V3e68ZiZDJBII8Boo/Eo+gmQiCNiYaS97jIIkCRHQFFeAZLQCH1G\n2ksrwwCJfwQYZRog8Y5QZaS9mLIPkNhGQFHuARLLCCVG2qsH9QMk3xFg9If/m0j7MqkUHaTb\n0Zjj/fXB5X3G+j2/SpvNqCGlrGiKzmTaFzR8MUG61n9lUTQkbu+/t9jXp+5sNuOFlJ4ish14\nGmjSg1QUt+otket3nLwVL0id90Umb0YGyVmPjiIvOvCkD+mrJlSa4lH9XLd/cTiZa/25s8Vm\nDJC89YRlxK8na0+qkI7m9vmmp9e7Ij8OprrTdDMHi001SHx6gjAKoSdfT2qQnndtzoU51neR\nbu+3F+/+Y7MpnRHVI8lIR884gasWV2qQjDnUDza0Hw7/iQqSJB9+RtpqZuO7itGlCKl6sOFY\n3dlpPhz+kxkk7yOpjcQihnUbXYqQqvtI9+aB7OwheR9HbRsOMazeiBJ/Oa65l+YaMHj9W3xO\ntdmUThiS70HUJuETxyKOIWtIP+ya/f6HSUjNI3H3z4NyhM3UIfkeQm0KHHEsZd3UIJ3r3wLd\nzf71fU3n1Gv1OybyZtqQPI+ftgDWWFa0UmqQnveOyurBhq/X9437mQ1xMtJe+DLxLOzQqUF6\n3qBU7d/f93XG3edU6ma6kPwOnfaCl41neYdLD9LjujfFqf2+rzOW9TO6rTZTheR13LTXeaCY\nVnmAFCFxlSQkv6Omvb5TjMfLbIBEGhETI+0VuYWY9HQCJNKIaBhpr8BNBkjNRQowAoyyCZAk\nR8TASHuFZRQgSY1QZ6S9tLILkERGgFGOARL7CE1G2ssp6wCJd0TejH4/l/YFCxMg8Y1QYqSy\nbmbZZOwJkJhGaDAKs0Ts2eTqCZAYRmyOEaOfjDwBku+IwIzEVoKgn0w8AZLXiMQVBfSTgydA\nch4RhhA3I0U/wzivVgwBktuIEITYGGmjmY/l6kUTINmPkCfkzUgbiUVMCzmCPCD5vASXTPqQ\n/AnlxOgd01pWzxHSr3ZtHBIPIV9G2iR84lrOqgESdYQkoZwZveNa0XoBEmmEHCFPRtoCWGNb\n1QoBEmmEFCEwGse2toMGSKQRMoT8GGkveNn4lniYAIk0Aox04lvo0gESaURkjLTXdxoxMlkP\nkEgjwCjlGL3MBkikEfEw0l6USccpZxAgkUaA0bbiJNQESKQRUTDSXn1bDJA6FynACDDaeoCU\nGCQoijxAkhwBRlkFSFIjFBlpL6pn/28u7QsmWOaQ2r9/KgrWETkxmmWTGydAqt7qmXUwA6RY\nFVmzyYpTlpCuvb/M3bGO2CAjNkEb55QfpNe7nL8cfbOOCM5IbmHIANo0p9wgPTr3kZhHbIBR\nCEDb5ZQbJKkRIRkxL4HwgDbKKS9Il+d9o/uO+Sc7d0j2jNgcaQPqx3WtdOOEFPfLcV2rgUU1\nN4b7SCqMtMks5X/t1GOD9ItdgSHtzdfjZnaPL7Nf+IrLzhSnsvMd1sw7QHJA5MdIG4lFXIta\nqRwgVRpu5rT8qMOpZlO0km7ckJwQZcOojWthK5QFpIO5LkK6mePT0MUcPycc1kaII/JipC3C\nL7bVHbZtQ9qb29UUj8Uf7Q7NF3yoXcx5bYQwoowZtbGt8HBtGFL97IZzpeS6+mUdSJe180oa\n8mKkvfzZ41vmQdoqpMelqO4hPXZfa19Vfm6znj8LHk1xWhohiMjHkfaql4txrUu3TUjkLp/b\nrEPzWMPC43zzkLwRuTPSXush4lzwgmUM6V58HmAw5nn7VZ4WfsCbhsSACIwoca55qTYH6Wv/\nvHE5rP1kVxaj259y4QnjI0gshtwZaa/sNGKFstbWIO3N6s9p9dkm0AweMe89P0MCERgFihXM\nXBuDdDFFddfnWiw+EHff7e8T32f+shp+RK6MtFdlwvHKGbQxSDtzq/+9Lf1h33Vwe1WY6kkO\n94VfyxpuRGCkGK+gVxuD1N6qLNy83Ic/952qR8zL08KvngwvIkdH2gtwYwHS8CJ1tj+3SPMv\nfnLsPDG9/k9ZP13cLPwiiRsSGEUUIL0vUmebch/JDCE9b40Ks1u6U8ULCYqiDJC6HxAftbMd\nkTej382kfblEAqSmrwPl90i2IxQZBV9Jc2zy0QRIYiO2y8iSTSacAElohA4j0bXCJGizmjKH\nVJ6qh+t6f0jOMULDkdACEQC0UU45Q7oXrwfjiomnLniMCM6If1mIA9qipmwh7es/I69+u7r2\n1+N2IxJmFBbQ5jiJQYr75bgoz2xwGRGSEdMK0ATUi+n66CUD6U92BYbUPG2u+puIeCDZMfJ2\npO1mJo4VrVZ+kE5mX70y5Pd+6Qk/DiMSYKQthRLf0g5eZpBie2YDGE3Gt74Dlhek5pkN+7WX\nBbIdEYSRuyNtGK4xLvMg5QRJZkQARc6MtDUwxLnYZQMkvxHiinJm9IlzyYsFSB4jhBWBUT/O\ndS8QIDmPEFXk6kh7ucvHu/45AyS3EYKIwGg1XgNMAZLLCDlFboy0l3Y8MfOwCpCsR0gpAiPB\nmNlMBUiWI2QUuTnSXp+JxW1nGCDZjJBA5MRIe1mmGrufTtqQbkdjjs2fDZ2K95u6lp/NB3FT\nD5KXIjAKH7uhd5qQrp93cm2eIFe9Nuq9eYm5+s/yPqcubypB8lPkwEh7FW4mfkfP9CAVxe1R\nHqpnaX+b5+atMN/VizdWz9o+Ve/v2jl1eVMDkqciB0faq29zbQXSV02mrF4RtXmx4K/mLSub\nKaZ36vJmaEjeiMAontKHdHy9uPCjese86ie5+r3Fixekonfq8mZQSAyKrBmJrqT/9Un0kgUs\nZUjPuzbnonmFhc7N0Pn1o13/xml1UzrDpygeRl6EwCkWSMbUb91aPPoiLtWjDcXlER8kFkW2\njkQWDJsgcIoCUvVgw3Fw2/O8Sao6PyKDxKRImZGMoO1xSgxSdR/pXj2Q3RFxqd+q6Fi9l8QG\nIakxCiBoW5wCQPKp/43af4rP5q5+FaD6fZGLyTNMb0rHAklDUWhB2+EkDulnu2a//+HDoHn4\nrX7rSTN56vJmIpDCMlIV1Mv/umiVBqRz/Vug+m0om81r9VNdcytT/3apc+ryZhKQginSdjMT\nz9IOXQqQnveOyure0Ffv2QonUz2N7jR4voP+MxsSuDXSpkKJc5GHKX5Ir8fn6tef230295On\nLm5GDwmMBnGudPlih/S47k3RvB5q85Tv5tTPZkncjB1SAEfaMtxiXe6SRQ6Jq7ghgdFarGte\nKEBiGgFG4rEufP4AiWWEPCM3R9qrnz/m9c8ZIPmPAKPAMRtgCpB8R8gqAqO5mCH4B0h+I0QZ\nOTnSXuIh49bgFyB5jBBUBEZecTOhBEjOI8QUuTDSXrupxA7oEyA5jpBi5OBIe3mmFr+iOkBy\nGiGjCIxCxQ/pdwNLgEQaIcLI3pH2ekw8SUqARBohoAiMdBKiBEikEeyKrBlpr79txW8JkEgj\nuBnZOpJbUv/jkdylChMnJUAijeBVFAcjH0LQNKQESKQRnIr0GTERAqdOgEQawcjI0hHvehEg\nBE1ukHxegksmBUjuiuwYMS4SWUIb4hQK0h/t2iKkxBiFI7QRTYAkN4JFkZ0jhhWhQmgLnABJ\nagSHopCMtAV1Y1naoQMkmREMjGwceawAbTZzsS3xUAGSxAhvRRaMHA+8thRKrCtdPEDiHxGO\nkaMjbSJ28S54uQCJe0TkN0faMFzjXfYSARLviKhvjrQ5+Me8+lkDJM4RYBQkZgNMARLfiFgd\naa98odgteAZIXCPASCV2Ec4BEs8IcUYOjrRXebj4XTgESBwjwCiy+KGsB0j+I2QZ2TvSXscR\nJiBnFCD5joiKkfaSTaWglACJNEKQka0j7R2xx0IAABkKSURBVOWZWKEoARJphJgiMApQCEqA\nRBoBRsknTAmQSCNkGFk60l6K6SdICZBII/QZSa2t//ZI6jLJJkMJkEgjBBhZOZJYUD6EUtfE\nTwmQSCPYFakyYiKUOidWSng5LtIIbkY2jjjXjgChtDWxUbKG9JNdGUBKg5EsobQ5cVACJNII\nVkZ0RyzLJByhlDX5UgIk0og0GakQSpmTByVAIo1gU0R35LUitAV1Y1rkoXKkBEikEekw0mYz\nF+NSl85JEiCRRiTASFsKJe4lLxUgSY1gYUR05HTotYnYxbzuBQIkmRHhGG321mgq7uXPGSBJ\njPBWJHlzpM3BP24EPAES/4hAjFwcaSPgjN2CZ4DEPcKTkdzNkfbSl4ldhHOAxDsiBCMHR9oL\nXjp+GPYB0nyXnSlOZeeEUzE4YTjCh5HYzZH2Mg8Wvw6bAGmuU/209OIDZ1+fsFsYIc7I3pH2\n6lZLwMpKgDTZzRyfhi7m+D7h2xS3x60w3/Mjors50l7N0STgZiJAmujQfMHnT6VO5vr875c5\nz4+I7OZIe/VGmwSiJkCa/bL26w7m/qhuqA7z5wWjBAtKKVtIpdm332B4EzUeIcjI1pH28kyr\nYJSyhXSpf55rvoEEJDCKpiCUcoV0Lz4/yAlAojKydKS9JNNNnFKmkMpi//mAHVJKjP7LOZGL\nI5kopUwh7bu/NComIfVeC0lCkR0j7VW4kcQkZflyXPfd/t75sHnU7q7zqJ3lQdReiGnGwWcB\nkROkP9gVI6Sr2fc+PtePO1zNaX6EGyQpTfBEio/PCqJMId0HjijPbAjwRxQOR1Z7pYaKW4RD\nq4cvQ0jHzk+dzY+eu/rD/fyX9P5CVhBTDn9mvhozAe9IBy5HSGYEqayf/b30JUwvIiSHKVlO\nrGuePRqiTCG5jJh8XTs3TsQD47kCtH1Mx7K4Q0VHBEjkEXOQHDlRjw7XmoAdy+wQARJ5xDIk\nN07kY8S9SkBnKXtD9Yt/AxJpBAWSCyf6wZJaN6BT58DngwiQyCPokOw52Rw27fW2rZz1DBAB\nEnmELSRbTlbHT3v9pZ2vnglEgEQe8fs6WU2WR1J7QSYVk55pQ4BEH/H7ThFhgqalWPUsIQIk\n8ojfj5LTZH90tVesdPwenFo8aoqQbkdjjs2zsDuvKzd96tKmDiQ3TuSbJntO2qvdN4GVz9jq\n8dKDdP28ulzndeWmT13c1ITkxElQUz9tG6NY1nToaIdKD1JR3B7lofrbhe6zrydPXd7Uh+TA\niY7Jm1M3sLGLfpDUIH3Vf/5TmqL3unLTpy5vxgLJnpOSpl5gM5fN0VGEdDS392bndeWmT13e\njAuSLSe7w6W9uHLJ7qioQnretTkX9YsHd198ZPrU1U3prCFZcoKmeLI3pAvJmEP9sMJjgGP6\n1JVN6cz/Vclqsj1y2gtuGzmyiQpS9bDCsbqz08MxferKpnQNJHdNQjdN0GQZG5te9ZFThFTd\nG7pXD2T3cEyfurIpXQeSOycpTOA0Ez+ZYZ2jJv5yXHMvzdVhUEziKCw2pRtBctVEvmmS+2PB\nBBMg4N3weFlDmlxS881+/86bq3ReV27u1KVNNUiunAQ1tWmvffv41rhw04dKDVLzYnL1S2N1\nXldu6dS5TWVIbpromLzedfOVNpJ3/tdEt4WDpAbpeT+orB5W+Oo9W2H6VP1nNtCubNya2sDG\nvtXjowbpeYPSvphc53Xlpk9d3IwHkosmG0ysnF6BzVq0I6MH6XHdv19Mrvu6cpOnLm5GBsmF\nk7YmNJnNQVGExFWUkOw12WECJ9lsjwYg0UY0vxSDpgyyJgRIFiO6v2OW1mR/ELXXXsI5sgEk\nxxHjp2wIa7LnpL0kU4iNzThAIo2YewZUbJratJdsDPEpIQRIpBHLTyiU1eTB6Z32kvbMfwdI\n1hwkQCKNoDw/N3ZNbRDBVPf4ABJpBAWSEyc7TZycXoGNS+MjA0ikEXRILpzUNU0HNhPNHRRA\nIo2wheTAyVJTME7o1fLhACTSiJ/qoCnPKEcCkEgjfuokrckWEzjJRT8GgEQa8dOo2G6boIk3\n290PSKQRY0iunGQ1gZV3jjsckEgj5iA5crLbh+6cwGom/106DJBII5YhuXEKralNexVbx3jd\nxQIk0ggKJCdOlruTfwFABE/iL8clsa4HFynACDokF07qmqaDFousIQl/f4dihOTAyVJTME6I\nFCCRRvyxCprQuNeRACTSiD+2xYcJnFQaHANAIo344yBxTdJ/44Rcm9n9gEQaMYTkqskOk9ur\nrYCVSCs7HJBIIyYhuXKy1OTBCaz8I+5iQCKNWIDkpskWE4MmsLLKcqcCEmnEGiQ3TtaaODlB\n1XSO+xGQSCNokFw02WMS0NRLZHk2CV9yzQCJNMICkgsnB03SnLpBy3qARBphDclekwumkJrQ\nYoBEGvFzXaSawCmCAIk04udO0prcMEGTboBEGvHzKOnbJldPYKUTIJFGjCG5crLT5MkJrKRr\ndzEgkUbMQXLkZKmJiRNYsTXeqYBEGrEMyY2TrSZmTlBl38J+BCTSCAokJ07WmmQ4gdVSlD0H\nSKQRdEgunOw1yXJ6pbMig1wQ/ksLSKQRtpAcODloCsLpncz620yARBrxp7o4NQXlhGbCqwiR\nRvypk7QmJ0zgpJw1JMvXZtogJGdOVrdNrp5gSidAIo0YQ3LlZKfJhxNMhQyQSCPmIDlystTk\nzQmmxAMk0ohlSG6cbDXxcIIpmQCJNIICyYmTtSZGTjDFGCCRRtAhuXCy18TNCbR8AyTSCFtI\nDpwcNElyEqGlPZ+33mUEJNKIX6oi1RSKU3IJ0+kHSKQRv7TJa3LCBE5WcdDpB0ikEb8Mkr9t\ncvUEUzoBEmnEEFIoTT6cYCpkgEQaMQnJnZOlJm9OMCUeIJFGLEAKpomHE0zJBEikEWuQnDlZ\na2LkBFOMARJpBA1SOE3cnMDKN0AijbCA5MrJQZMUJ6iyD5BII36tilSTMCewIgVIpBG/tllr\nsubkhCkUJ5W0kVACJNKIXwfJ3zg5ctq6KZsAyfIiBRgxhBT3jRNMzcTGZvytAYk0YhJSCjdO\nMLWcI5txgEQasQApLU0wJRRejos0Yg1SkpxgijFrSL+zKytIyWoCK+8yhXTpfdHqjacNpA1w\ngir78oR066m5CUDajCawopUlpFsxgHRYG/Gjyk2TNSdrTSE5+aW92gXLEdLF7HuQLua8NuJH\nWyBNUd84hU4bCaUcIZnTYwDpsvYVPwZFe+OUAat+2oDe5Qjp9uhDOpjr0RSnpRFDSHHfOOXL\nqhcgWV4kl6/pQ6rbL5x9EpIPJwVNmbOqAqTFi+TyNab3wdfjUZ4WfsBbgpTYjRNU9QKkzkVy\n+ZrxF5VmN3/2NUip3jjBFFeANHda74lONEiJ3zjBlEeAtHja+1MWkDZx4wRTtgHS41GY8vnf\n+8KvZc1vVbFqCsEJplZShHQ7GnO815unwhSn8v2J79cXdU5d2vSGdDKn+sGG6/zZf2uz1rSh\nGyfvtFe7YHqQrvWdj6Iisa833/f1y6L5os6pi5s+kOp/nwOrFn6R1IEUlJP9jVNKrPppS/BM\nD1JR3B7loVq+3+a5eSvMd/OJQ7PKO6cub3pDet4aFWa39OyGESRHTaE5pcuqlzYSSmqQvupb\ngNIU1Y9W1/qE8+sTzerunLq8GeJu2CSkoJz8NW2FVT9tQO/UIB3N7b15MNU9pddzsO/vZ5R2\nTl3eVIbkqkmb0xZV9csD0vOuzbkwx+ou0otC88/e3JuNzqmrm9KtQgrKiV/TxkXVbRWSMfVT\n3IpHX8TZfD2SheSsKR5OGYiq2hSk6sGGY3VnpyOi/pktbUhBOYlpykVUXeKQqvtI9+qB7I6I\nXfVweISQ/lwVRlNsnHISVRUKkk/9b9T+U7Sbx/qBuOZTxdQZZjalayC5aQrFSVpTdqLssob0\nv3bNfv/Dh0Hz8Fv1FJ2uuc+pK5thIQXlZH/jFJKVfdqrXTA1SOf6xude/Tlds3mt/wL8A+lz\n6sqmBiRHTaE5xc2qn7YEz9QgPe8dldWDDV+jZzY8AjyzwfZaT0IKyslfU1KsemkjoaQG6XmD\n0v59967/p94vGrvJM4w3lSG5atLmlKqqJm03o/QgPa779yuOlPXTuD8zzPDUxc0YIAXlxK8p\nYVFt+ULiKh5Izpri4bQBUW2AZHmRAoywgBSUk5imTYkKYQqQSCOsIblrio3TtkSJmQIk0oi/\nVLlpCsVJWtPmRPGaAiTSiL+0OWoKdtcpjCltAuwBUmhI6XAKdjtFT5sLJUCSHDGE5KUp2G+d\nYjb1TtsNJUBiGzEJKUlOEZt6pc2GEiA5jliA5Kcp2BP2kjT1SpsNJUAijViDlDqnRERNpA3o\nHSCRRtAgeWoK9rdOmxQ1DpAsL1KAERaQNsJpQ6IAiXiRAoz4a1VITaH+rj0nUYC0cpECjPhr\nm7WmwHedRE1pU+AJkGYuUoARfx3kwCns4+TCprQtcARIw4sUYMQQkrOmwM/YC3I7lTgyQHpf\npAAjJiElySmoqaSMBYbk8xJcMilD8tDk6IlJk66pUdqO3oWC9D92ZQLJj5OTJ1ZOMYkalwIr\nQCKNoEHy0+TiiVtT5KI+RccKkEgjLCBthFMqotqUWQESacTfqkJqsuckpCk9UW1BVQESacTf\n2qw1hb1xkjWlTcMpQKJepAAj/jYoBU6SprRxOARIqxcpwIghJEdNHpx8NAnfTiVlC5DmL1KA\nEZOQkuQUwlT8tABp6iIFGLEAyVVT2N86KZuKlBYg9S5SgBFrkFLnFBhUZMgAqblIAUbQIDlr\nCvsUo7hBTZSCJ0AijbCAtAlOcYJqipMTIJFG/P2ZNSY3Ta6cJDTF7OlVLKQAiTTi7+/sNTly\n0vrFU6qgmvREARJpxN97OWhS4CRiSluKTUFFARJpxN/HuWjS4sRuStuIRfycJkUBEmnEBCR3\nTaqc2E2lYUuEU1cUIJFGzEHy0KTPScxUtLSkOD0DJNKIRUg+miLhJOkpOlqANHORAoxYh+Sl\nKRZOgTxFYQuQRhcpwAgiJD9N0XBS8KRFC5A6FynACBtInprAaVQKnPByXKQR/6gKqcnZE78p\nbUbD4uRkDem/7doSJDdNfp48ODGb0vYzUyycAIk04h+DHDgp/LQnYUobznJ6oACJNGIIyVmT\nwmMREqa0wZAKCgqQSCMmIaXOicdU7LZ4OK2CAiTSiAVIHprC/+JJ3lOktLg4zYICJNKINUh+\nnEI/LSKsp4ho8XEagQIk0ggaJD9NoZ+0p+dJ2RYnpxYUIJFGWEACpzRo8XL6DZBII/75zBqT\njybVXz5F4SkMLUDqXKQAI/75zl6TjycfTdymtDU1RcsJkEgj/tnLRZPCQxEiprQlfYqLEyCR\nRvxznJsmZ09MmphMaSMaFAEnQCKNmIDkpSkKTjymImOlxQmQSCPmIPlpcvTEr4n14QltSm1B\nNQESacQiJF9NwZ8DG4JTNKwCcQIk0oh1SP6aXDwJaBLhpK1KXhMgkUYQIXFo2j4nNVaSnACJ\nNOJfz2wweWsK/Oe4ipxCsxLSBEikEf96F7kmGVMBOQVi5a1pxAmQSCP+1ctKkz8oR07cphQ4\nCavi1ARIpBH/GmeryROUjyZOU3qchFgx3TgBEmnEBCRXTV6g/DnxmNLG9CkWTng5LtKIOUge\nmoI/yUjI1IZYBYX0X3blAMlLkzMoVk7buC81KKgmQCKNWIfkq8kNFK+mWJ/Ll4ImQCKNIEJi\n0BT6DwgDeVJV5YbJThMgkUbYQGLRZM+JXZMYJx1WwpoAiTTi31UJaJIwJe0pICtHTBRNgEQa\n8e82a03+oBw5MZsK5EmelYwmQCKN+PcgF05+oHw0cZoK60lKlSumeU2ARBoxhOShyQuUPyce\nUxqc2E2xagIk0ohJSJ6cgv8iF6YYMQ01ARJpxAIkT03OoOLilLQpDk2ARBqxBomBU/CnwUpx\nStOUO6a/ABJ9BA0ShyYXT9FySs2Uh6ZMIV36X3QqTHEqF0ZYQNLixKtJ4Pe7OqZCYVKEdDsa\nc7wPF/Jl1252Tl3adIB06z8rfV8/T323cK3/U5WAJm5TIpyCswpx06QH6Vqv3qLsL+TT5KmL\nm/aQbkUP0rcpbtVp3/PX+j9t1pr8QTly4jMlyikQK3tMdpr0IBXP1VsezKm3kG/mWFY/eB17\npy5vWkO6mH3vi07m+vzvlznPX+v/9HPR5AnKRxOPqSCcZFkJYlKD9FURepSm6C3kQ3P+ap13\nTl3etIb0nNz7ooOpfsC8mcP8V/xnIkdNXqD8OfmaCspJQpXQTZMapKO5zS/kap13Tl3etIZ0\ne/QhGdP9Z/JaT0Hy5eTsiUmTjykNToykHDCtaVKD9Lxrcy7qH+TGC7k0+96pq5vW8UHy1eQM\nKgJOiqh0NMUIyZhD/bDC1EK+VD+0pQSJQZMbKFZN0TwxNpwovpsmRUjVgw3H6s7OcCHfi8Mj\nQUg8mlw8xcZJBVVQTGNNipCq+0j36oHswUIui/1geQtDKia/kfXrJaGss16BTLM6DAYLeb8b\nLu/VTesmHrW7Lz1q5zDCuaDDcNVSHNat80B3byHfd/v76wztqcub3pDO9ePo1/rx+JmzO4xw\nDqstxWlqkJrVe68en+su5KvZ985Qn7q86Q2J8MwGhxHOYbWlOE0N0vPeUVk92PDVW8j31pHg\nMxseH0jNv7v6B8/9wtkdRjiH1ZbiNDVIzxuUdvV+FvKxc3dqN3WGiU1/SGX97NelszuMcA6r\nLcVpepAe1/179X4Wcvdxic7yXtwMcBU2fEhw1RIcJhMgJTMNVy3mACmZabhqMQdIyUzDVYs5\nQEpmGq5azAFSMtNw1WIOkJKZhqsWcxu4CgjpB0gIMQRICDEESAgxBEgIMQRICDEESAgxBEgI\nMQRICDEESAgxBEgIMQRICDEESAgxBEgIMQRICDEESAgxxA9p9Cbn0+8QLT+ssxlg2qN60c1Q\nwzpvxS0/rRQ/amV1dW4zFySR2CGN3uR8+h2i5Yd1NgNMe1RvBMK5M5eGXUNetXvRbPK5HQ1r\nJtwmP5dK3JBGLwU+/Q7R8sM6mwGmVR2cXv/ZZdjnrbgDTDvWc058O3I0rP7ep/ptINiXSLC4\nIY3e5Hz6HaLlh3U2A0yrP8EJaWlY5624A0zzeSct2rDCtO/hyr5EgsUNae5NzgfvEC0/bLwp\nO+1u9pyQloZ13oo7wLT3O2mxsZ0ZVg9gXyLB4oY08/+v4TtEyw8bbQpP2xu3N5tyGNZ5K+4A\n086vH+3YbiSmh53MZf6CJFAgSMN3iJYfNtqUnXY2X6yHf3k/tm/FHWDa41I9FlBcRIc9fy4+\nLVyQBAoDafQO0fLDhpuy0+ofRuQhvfdj+1bcAaa93kJIdtjlUNQTAKn9flN7YvwO0fLDBpvC\n03bVA8XikNr92L4Vd4Bpl+q24smW7SZpZhnUEwDp3eSbPI/fIVp+2GBTdtqx/hmI8/AvXTX+\n1bY0bVc/plbysZ1ZBvWjkOxLJFgyj9r13uR86h2i5Yf1NqWnTb/3vNAwgUf2l6axs51bBqO3\nFk8qbkjjNzmffIdo+WHdTfFp/JDW9+Od8fotTWtuJBh/azUa1vweqf5RlX2JBIsb0uhX09Pv\nEC0/jHOdrU+rE31mQ++qtW/FHWDayVRPfTvxre3pZzaUh+o+Ep7Z0NZ5v+d6Yc28Q7T4sCP3\nbcTyVWtPDDGs81bcAabtpY/a67l2w7cLTyt2SJ33e673UveHntU3QGccxv7D1vJVa08MMuzz\nVtwhpkkftXrC7jL8XFql9/AIQhEGSAgxBEgIMQRICDEESAgxBEgIMQRICDEESAgxBEgIMQRI\nCDEESAgxBEgIMQRICDEESAgxBEgIMQRICDEESAgxBEgIMQRICDEESAgxBEgIMQRICDEESAgx\nBEgIMQRICDEESAgxBEgIMQRICDEESAgxBEgIMQRICDEESAgxBEgIMQRIGjVvKah9KRBjOJoa\nAdLmwtHUCpA2FY6mVoC0qXA0ZbrsTFG/T/fTy+n9Pt3XvTH766P7o93zfLvX+e4HU5y1Li/y\nDJBEOpiq/aMCcn5vXuoTzaUDad85X1FtQlKiAZJEV7MvH+XeXGsgt8etMF+PR2Fuj8eX2X0g\nfX0+aaovuVSfRCkGSBIdTPn8b2kOFZDqZ7nrZ7PqDenw+uS++vD7gTtO6YYDJ5F519Ko/jkZ\nc7jd3h8NPtlsAlKq4cBJNA3pca7uBhV3QNpgOHASdTx0IT1/ijvtuveRAGkz4cBJdGjvDb3u\n+1zN8XPC+D7SAZBSDwdOovrRuMelAdI8MPcUs6senZt/1K76QkBKNRw4kZrfDzV3h+rtJ6kn\nm7rvmd8jPR6AlG44cDJddsYcn44qGofXkxeaZza8H+V+PbOhaJ/Z8PkvSi8cOOFAI49wmIUD\npDzCYRYOkPIIh1k4QMojHGaEGAIkhBgCJIQYAiSEGAIkhBgCJIQYAiSEGAIkhBgCJIQYAiSE\nGAIkhBgCJIQYAiSEGAIkhBgCJIQYAiSEGAIkhBgCJIQYAiSEGAIkhBgCJIQYAiSEGAIkhBgC\nJIQYAiSEGAIkhBgCJIQY+v8F152nm1fpBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Performance of `svm'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "svm.base.tune3 <- tune(svm, gross_2016~., data = train.svm.base,\n",
    "              ranges = list(epsilon = seq(0.2,0.3,0.01), cost = 2^(0:2))\n",
    ")\n",
    "options(warn = 1)\n",
    "print(svm.base.tune3)\n",
    "plot(svm.base.tune3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "best.tune(method = svm, train.x = gross_2016 ~ ., data = train.svm.base, \n",
       "    ranges = list(epsilon = seq(0.2, 0.3, 0.01), cost = 2^(0:2)))\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  eps-regression \n",
       " SVM-Kernel:  radial \n",
       "       cost:  2 \n",
       "      gamma:  0.125 \n",
       "    epsilon:  0.25 \n",
       "\n",
       "\n",
       "Number of Support Vectors:  1328\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm.base.tune3$best.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the optimal value of the hyperparameter, I can make the prediction for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "85383309.2039541"
      ],
      "text/latex": [
       "85383309.2039541"
      ],
      "text/markdown": [
       "85383309.2039541"
      ],
      "text/plain": [
       "[1] 85383309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.svm.base.tune <- svm.base.tune3$best.model\n",
    "model.svm.base.tune.pred <- predict(model.svm.base.tune, test.svm.base) \n",
    " \n",
    "error <- test.svm.base$gross_2016 - model.svm.base.tune.pred    \n",
    "rmse(error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(data): objet 'test.svm.base' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(data): objet 'test.svm.base' introuvable\nTraceback:\n",
      "1. plot_ly(test.svm.base) %>% add_trace(y = ~test.svm.base$gross_2016, \n .     name = \"trace 0\", type = \"scatter\", mode = \"lines+markers\") %>% \n .     add_trace(y = ~model.svm.base.tune.pred, name = \"trace 1\", \n .         type = \"scatter\", mode = \"markers\") %>% layout(title = \"Gross revenu of movies in the data set and prediction from the svm algorithm\", \n .     xaxis = list(title = \"\", zeroline = TRUE), yaxis = list(title = \"Gross\"))",
      "2. eval(lhs, parent, parent)",
      "3. eval(expr, envir, enclos)",
      "4. plot_ly(test.svm.base)",
      "5. is.data.frame(data)"
     ]
    }
   ],
   "source": [
    "svm_base_pred<-plot_ly(test.svm.base) %>%\n",
    "add_trace(y=~test.svm.base$gross_2016, name = 'test set', type = 'scatter',mode = 'lines+markers' )%>%\n",
    "add_trace(y=~model.svm.base.tune.pred ,name = 'predictions', type = 'scatter',mode = 'markers' )%>%\n",
    "layout(title = 'Gross revenu of movies in the data set and prediction from the svm algorithm',\n",
    "         xaxis = list(title = '', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Gross'))\n",
    "\n",
    "embed_notebook(svm_base_pred,file=paste0(\"plotlyJupyterHTML/\",\"svm_base_pred\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write.svm(model.svm.base.tune , svm.file = \"model.svm.base.tune.svm\", scale.file = \"IMDB-regression.scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has trouble predicting the outlier since most of the predicted point are between 0 and 200 million dollars. Also if we zoom we see taht the model is quite good at predicting if the shape of the curve, but miss the real value of the variable \"gross_2016\". Let's see if adding more feature will help the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_svm<-train[,c(cont_var),with=FALSE]\n",
    "test_svm<-test[,c(cont_var),with=FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After coping all the continous variable in the data set, I drop the \"profit\" variables and I keep only the row without missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_svm <- train_svm[,!\"profit\",with=FALSE]\n",
    "test_svm  <- test_svm[,!\"profit\",with=FALSE]\n",
    "\n",
    "train_svm <- train_svm[complete.cases(train_svm)]\n",
    "test_svm  <- test_svm[complete.cases(test_svm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.svm.cont <- svm(gross_2016~.,  scale = TRUE, data = train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultats.svm.cont <- predict(object = model.svm.cont, newdata = train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train_svm$gross_2016 - resultats.svm.base:\n",
      "\"la taille d'un objet plus long n'est pas multiple de la taille d'un objet plus court\""
     ]
    },
    {
     "data": {
      "text/html": [
       "94543061.3671373"
      ],
      "text/latex": [
       "94543061.3671373"
      ],
      "text/markdown": [
       "94543061.3671373"
      ],
      "text/plain": [
       "[1] 94543061"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error <- train_svm$gross_2016 - resultats.svm.base\n",
    "rmse(error) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the continuous variables to the model doesn't make it more precice. Like most algorithm, the SVM algorithm is less accurate the more feature we use. Let's see if tuning the model can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in print(svm.tune): objet 'svm.tune' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in print(svm.tune): objet 'svm.tune' introuvable\nTraceback:\n",
      "1. print(svm.tune)"
     ]
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "svm.cont.tune <- tune(svm, gross_2016~., data = train_svm,\n",
    "              ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:9))\n",
    ")\n",
    "options(warn = 1)\n",
    "print(svm.cont.tune)\n",
    "plot(svm.cont.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter tuning of 'svm':\n",
      "\n",
      "- sampling method: 10-fold cross validation \n",
      "\n",
      "- best parameters:\n",
      " epsilon cost\n",
      "     0.2    4\n",
      "\n",
      "- best performance: 6168608417283058 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAV1BMVEUAAABNTU1NTf9XV/9i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\nUZYQMoQShCoAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Performance of `svm'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn = 1)\n",
    "print(svm.cont.tune)\n",
    "plot(svm.cont.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "svm.cont.tune2 <- tune(svm, gross_2016~., data = train_svm,\n",
    "              ranges = list(epsilon = seq(0,0.5,0.2), cost = 2^(0:2))\n",
    ")\n",
    "options(warn = 1)\n",
    "print(svm.cont.tune2)\n",
    "plot(svm.cont.tune2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "best.tune(method = svm, train.x = gross_2016 ~ ., data = train_svm, \n",
       "    ranges = list(epsilon = seq(0, 1, 0.1), cost = 2^(2:9)))\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  eps-regression \n",
       " SVM-Kernel:  radial \n",
       "       cost:  4 \n",
       "      gamma:  0.08333333 \n",
       "    epsilon:  0.2 \n",
       "\n",
       "\n",
       "Number of Support Vectors:  1519\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm.cont.tune$best.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "86767051.5595682"
      ],
      "text/latex": [
       "86767051.5595682"
      ],
      "text/markdown": [
       "86767051.5595682"
      ],
      "text/plain": [
       "[1] 86767052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.svm.cont.tune <- svm.cont.tune$best.model\n",
    "model.svm.cont.tune.pred <- predict(model.svm.cont.tune, test_svm) \n",
    "error <- test_svm$gross_2016 - model.svm.cont.tune.pred  \n",
    "rmse(error) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding features to the model didn't help to reduce the root mean square error of the model. So for now, 85383309 is the mark to beat with the other algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Xgboost\n",
    "This algorithm has for advantage to be really fast, he can handle very well sparse matrix and missing data.\n",
    "\n",
    "Since most variables in the data set are not correlated to the variable of interest, using all of them in the model is not really a good idea: it will just add a lot of noise to the model and can create some overfitting problems. But this algorithm is really good at picking the important feature in a model and since he is so fast, I took the opposite approach I used for the SVM algorithm: I use the most feature possible for my first use of this algorithm and I will prune the feature as a go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_names <- names(train[,!c(\"budget\",\"gross\",\"profit\",\"budget_us\",\"currency\",\"imdb_score\",\"director_name\",\n",
    "                                  \"num_user_for_reviews\",\"movie_imdb_link\",\"num_voted_users\",\"num_critic_for_reviews\",\n",
    "                                  \"movie_facebook_likes\",\"genres\",\"movie_title\",\"plot_keywords\",\"actor_1_name\",\n",
    "                                 \"actor_2_name\",\"actor_3_name\",\"V1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb<-train[,variable_names,with=FALSE]\n",
    "test_xgb<-test[,variable_names,with=FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I already coded the cathegorical variables as dummy variables, I excluded them from the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb <- train_xgb[,!cath_var,with=FALSE]\n",
    "test_xgb <- test_xgb[,!cath_var,with=FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then I normalize the continuous variables and coded the missing information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (f in intersect(variable_names,cont_var)) {\n",
    "  if (max(train_xgb[[f]],na.rm=TRUE)!=1 | min(train_xgb[[f]],na.rm=TRUE)!=0) {\n",
    "    train_xgb[[f]] <- scale(train_xgb[[f]])\n",
    "    test_xgb[[f]]  <- scale(test_xgb[[f]])\n",
    "  }\n",
    "}\n",
    "\n",
    "train_xgb[is.na(train_xgb)]<--1\n",
    "test_xgb[is.na(test_xgb)]<--1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use xgboost, I have to feed the function a matrix, so I have to convert the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chr \"gross_2016\"\n"
     ]
    }
   ],
   "source": [
    "drop_col_names <- names(train[,c(\"gross_2016\")])\n",
    "str(drop_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb_matrix <- xgb.DMatrix(data.matrix(train_xgb[,!drop_col_names,with=FALSE]),\n",
    "                                label=train_xgb$gross_2016,missing=-1)\n",
    "test_xgb_matrix  <- xgb.DMatrix(data.matrix(test_xgb[,!drop_col_names,with=FALSE]),\n",
    "                                label=test_xgb$gross_2016,missing=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I set the pameters for the algorithm. Since the data is normalize, I'm not interested in having the rmse printed for each iteration of the algorithm, so I didn't initialise the watchlist argument. Also, after trial and error, I realised that 500 iterations where enoupht for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param <- list(  objective           = \"reg:linear\", \n",
    "                booster             = \"gblinear\",\n",
    "                eval_metric         = \"rmse\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb <- xgb.train(   params          = param, \n",
    "                    data                  = train_xgb_matrix, \n",
    "                    nrounds               = 500,\n",
    "                    verbose               = 0, \n",
    "                    early_stopping_rounds = 20,\n",
    "                    missing               = -1,\n",
    "                    maximize              = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I took the model greated by the algorithm and predited how much that each movie in the data set should gross at the box-office and compare those prediction with the real values. To do so, I scale the prediction to match the data set and calculated the rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred<-predict(model_xgb,test_xgb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "95480460.0796237"
      ],
      "text/latex": [
       "95480460.0796237"
      ],
      "text/markdown": [
       "95480460.0796237"
      ],
      "text/plain": [
       "[1] 95480460"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaleList <- list(scale = attr(train_xgb$gross_2016, \"scaled:scale\"),\n",
    "    center = attr(train_xgb$gross_2016, \"scaled:center\"))\n",
    "\n",
    "pred_unscale <- pred * scaleList$scale + scaleList$center\n",
    "error<-pred_unscale-test_xgb$gross_2016\n",
    "rmse(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.save(model_xgb,fname=\"model_xgb_1_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This model did worst than the best SVM model: maybe the cathegorical variables don't offer usefull information to the algorithm. In the next model, I'll use only the continous variables that I choose for the last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb <- train_xgb[,intersect(variable_names,cont_var),with=FALSE]\n",
    "test_xgb <- test_xgb[,intersect(variable_names,cont_var),with=FALSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xgb_matrix <- xgb.DMatrix(data.matrix(train_xgb[,!drop_col_names,with=FALSE]), label=train_xgb$gross_2016,missing=NA)\n",
    "test_xgb_matrix  <- xgb.DMatrix(data.matrix(test_xgb[,!drop_col_names,with=FALSE]), label=test_xgb$gross_2016,missing=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb <- xgb.train(   params          = param, \n",
    "                    data                  = train_xgb_matrix, \n",
    "                    nrounds               = 1000, # changed from 300\n",
    "                    verbose               = 0, \n",
    "                    early_stopping_rounds = 20,\n",
    "                    #watchlist             = watchlist,\n",
    "                    missing               = -1,\n",
    "                    maximize              = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83959483.9582247"
      ],
      "text/latex": [
       "83959483.9582247"
      ],
      "text/markdown": [
       "83959483.9582247"
      ],
      "text/plain": [
       "[1] 83959484"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred<-predict(model_xgb,test_xgb_matrix)\n",
    "pred_unscale <- pred * scaleList$scale + scaleList$center\n",
    "error<-pred_unscale-test_xgb$gross_2016\n",
    "rmse(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.save(model_xgb,fname=\"model_xgb_cont_var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the cathegorical variables help the xgboost algorithm greatly! Let's see if using even less variable will help us make a better model. For the next model, I used only the variables whom where at least midly correlated with the \"gross_2016\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_var<-names(movies[,c(\"budget_2016\",\"gross_2016\",\"dir_mean_gross\",\"act_1_mean_gross\",\"act_2_mean_gross\",\"act_3_mean_gross\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb <- train_xgb[,min_var,with=FALSE]\n",
    "test_xgb <- test_xgb[,min_var,with=FALSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xgb_matrix <- xgb.DMatrix(data.matrix(train_xgb[,!drop_col_names,with=FALSE]), label=train_xgb$gross_2016,missing=NA)\n",
    "test_xgb_matrix  <- xgb.DMatrix(data.matrix(test_xgb[,!drop_col_names,with=FALSE]), label=test_xgb$gross_2016,missing=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb_tune_1 <- xgb.train(   params          = param, \n",
    "                    data                  = train_xgb_matrix, \n",
    "                    nrounds               = 1000, # changed from 300\n",
    "                    verbose               = 0, \n",
    "                    early_stopping_rounds = 20,\n",
    "                    #watchlist             = watchlist,\n",
    "                    missing               = -1,\n",
    "                    maximize              = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83748392.8717631"
      ],
      "text/latex": [
       "83748392.8717631"
      ],
      "text/markdown": [
       "83748392.8717631"
      ],
      "text/plain": [
       "[1] 83748393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred<-predict(model_xgb_tune_1,test_xgb_matrix)\n",
    "pred_unscale <- pred * scaleList$scale + scaleList$center\n",
    "error<-pred_unscale-test_xgb$gross_2016\n",
    "rmse(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is the more efficient so far, but I used almost only the default parameter of the xgboost algorithm to do it. By tuning the hyperparameter I should be able to make a more efficient model to predict the gross of the movie in the test set. In the cell below, I calculated the rmse of different model using a value of eta from 0 to 0.99 by 0.01 increment. The cross validation is made using a 5 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,0.99,0.01)){\n",
    "    set.seed(383)\n",
    "     model_xgb_cv <- xgb.cv(params=param, eta=i, data = train_xgb_matrix, nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse<-rbind(xgb_mse,c(\"index\"=i,lapply( model_xgb_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_mse_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_plot<-plot_ly(xgb_mse) %>%\n",
    "add_trace(x=~index,y=~test.rmse.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the rmse during the cross validation',\n",
    "         xaxis = list(title = 'eta', zeroline = TRUE),\n",
    "         yaxis = list(title = 'rmse'))\n",
    "embed_notebook(xgb_mse_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_mse_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.rmse.mean</th><th scope=col>train.rmse.std</th><th scope=col>test.rmse.mean</th><th scope=col>test.rmse.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>34</th><td>0.33     </td><td>0.7073754</td><td>0.0264264</td><td>0.7763158</td><td>0.1146582</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.rmse.mean & train.rmse.std & test.rmse.mean & test.rmse.std\\\\\n",
       "\\hline\n",
       "\t34 & 0.33      & 0.7073754 & 0.0264264 & 0.7763158 & 0.1146582\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.rmse.mean | train.rmse.std | test.rmse.mean | test.rmse.std | \n",
       "|---|\n",
       "| 34 | 0.33      | 0.7073754 | 0.0264264 | 0.7763158 | 0.1146582 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.rmse.mean train.rmse.std test.rmse.mean test.rmse.std\n",
       "34 0.33  0.7073754       0.0264264      0.7763158      0.1146582    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse[xgb_mse$test.rmse.mean==min(xgb_mse$test.rmse.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the value of the eta that minimise the rmse of the test set used in the cross validation, I can create a more efficient model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb_tune_2 <- xgb.train(   params          = param, \n",
    "                    data                  = train_xgb_matrix, \n",
    "                    eta                   = 0.33,\n",
    "                    nrounds               = 500, # changed from 300\n",
    "                    verbose               = 0, \n",
    "                    early_stopping_rounds = 20,\n",
    "                    missing               = -1,\n",
    "                    maximize              = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83748395.6760708"
      ],
      "text/latex": [
       "83748395.6760708"
      ],
      "text/markdown": [
       "83748395.6760708"
      ],
      "text/plain": [
       "[1] 83748396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred<-predict(model_xgb_tune_2,test_xgb_matrix)\n",
    "pred_unscale <- pred * scaleList$scale + scaleList$center\n",
    "error<-pred_unscale-test_xgb$gross_2016\n",
    "rmse(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_pred.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_pred<-plot_ly(test_xgb) %>%\n",
    "add_trace(y=~test$gross_2016, \n",
    "          name = 'test set', type = 'scatter',mode = 'lines+markers' )%>%\n",
    "add_trace(y=~pred_unscale ,name = 'predictions', type = 'scatter',mode = 'markers' )%>%\n",
    "layout(title = 'Gross revenu of movies in the data set and prediction from the xgboost algorithm',\n",
    "         xaxis = list(title = '', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Gross'))\n",
    "\n",
    "embed_notebook(xgb_pred,file=paste0(\"plotlyJupyterHTML/\",\"xgb_pred\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.save(model_xgb,fname=\"model_xgb_min_var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classification\n",
    "## XGBoost logistic regression\n",
    "\n",
    "By zooming on any part of the last plot, we see that regression with the XGBoost algorithm has trouble adjusting to the variability of the data, i.e. the algorithm underestimate the profit of high margin movie and overestimate the performance of movie how lost a lot of money. If we simplify our goal and only are interested to know if the movie will be profitable, does the model will be more accurate? First let us look at the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.554491017964072"
      ],
      "text/latex": [
       "0.554491017964072"
      ],
      "text/markdown": [
       "0.554491017964072"
      ],
      "text/plain": [
       "[1] 0.554491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction<-test[,c(\"gross_2016\",\"budget_2016\",\"profit\")]\n",
    "prediction$pred_gross<-error\n",
    "prediction$pred_profit<-prediction$pred_gross-prediction$budget_2016\n",
    "prediction$pred_profit_binary<-0\n",
    "prediction[prediction$pred_profit*prediction$profit>0, \"pred_profit_binary\"]<-1\n",
    "\n",
    "sum(prediction[complete.cases(prediction),\"pred_profit_binary\"])/nrow(prediction[complete.cases(prediction),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous model class correctly about half of the observations in the test set. Not bad, but we can do better by using a algorithm taylor made for that classification. The first one I used is the xgboost for logistic regression.\n",
    "\n",
    "As usual, I started by created a modified train and test set to use with the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_names_log <- names(train[,!c(\"budget\",\"gross\",\"gross_2016\",\"budget_us\",\"currency\",\"imdb_score\",\"director_name\",\n",
    "                                  \"num_user_for_reviews\",\"movie_imdb_link\",\"num_voted_users\",\"num_critic_for_reviews\",\n",
    "                                  \"movie_facebook_likes\",\"genres\",\"movie_title\",\"plot_keywords\",\"actor_1_name\",\n",
    "                                 \"actor_2_name\",\"actor_3_name\",\"V1\")])\n",
    "\n",
    "train_xgb_log<-train[,variable_names_log,with=FALSE]\n",
    "test_xgb_log<-test[,variable_names_log,with=FALSE]\n",
    "\n",
    "train_xgb_log <- train_xgb_log[,!cath_var,with=FALSE]\n",
    "test_xgb_log <- test_xgb_log[,!cath_var,with=FALSE]\n",
    "\n",
    "for (f in intersect(variable_names_log,cont_var)) {\n",
    "  if (max(train_xgb_log[[f]],na.rm=TRUE)!=1 | min(train_xgb_log[[f]],na.rm=TRUE)!=0) {\n",
    "    train_xgb_log[[f]] <- scale(train_xgb_log[[f]])\n",
    "    test_xgb_log[[f]]  <- scale(test_xgb_log[[f]])\n",
    "  }\n",
    "}\n",
    "\n",
    "train_xgb_log[is.na(train_xgb_log)]<--1\n",
    "test_xgb_log[is.na(test_xgb_log)]<--1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I create a new variable \"profitable\" whom indicate if the movie was profitable or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xgb_log$profitable<-0\n",
    "test_xgb_log$profitable<-0\n",
    "\n",
    "train_xgb_log[which(train_xgb_log$profit>=0),\"profitable\"]<-1\n",
    "test_xgb_log[which(test_xgb_log$profit>=0),\"profitable\"]<-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I repeat the steps use for the regression with xgboost, but I changed the objective for the logistic regression and the evaluation metric for the binary classification error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb_log_mat <- xgb.DMatrix(data.matrix(train_xgb_log[,!c(\"profitable\",\"profit\"),with=FALSE]), label=train_xgb_log$profitable,missing=-1)\n",
    "test_xgb_log_mat <- xgb.DMatrix(data.matrix(test_xgb_log[,!c(\"profitable\",\"profit\"),with=FALSE]), label=test_xgb_log$profitable,missing=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param <- list(  objective           = \"binary:logistic\",\n",
    "                eval_metric         = \"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb_log <- xgb.train(   params        = param, \n",
    "                    data                = train_xgb_log_mat, \n",
    "                    nrounds             = 500,\n",
    "                    verbose             = 0, \n",
    "                    missing             =-1,\n",
    "                    maximize            = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having made the model, I have to make the prediction onver the test set and calculate the binary error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction<-data.frame(profit=test_xgb_log$profitable)\n",
    "prediction$output<-NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (rows in split(1:nrow(test_xgb), ceiling((1:nrow(test_xgb))/10000))) {\n",
    "    prediction[rows, \"output\"] <- predict(model_xgb_log, test_xgb_log_mat)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>profit</th><th scope=col>output</th><th scope=col>pred</th><th scope=col>index</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0                   </td><td>0.000003818766799668</td><td>0                   </td><td>1                   </td></tr>\n",
       "\t<tr><td>0                   </td><td>0.000000000203112957</td><td>0                   </td><td>2                   </td></tr>\n",
       "\t<tr><td>0                   </td><td>0.000347295281244442</td><td>0                   </td><td>3                   </td></tr>\n",
       "\t<tr><td>0                   </td><td>0.001790401292964816</td><td>0                   </td><td>4                   </td></tr>\n",
       "\t<tr><td>0                   </td><td>0.999916315078735352</td><td>1                   </td><td>5                   </td></tr>\n",
       "\t<tr><td>0                   </td><td>0.000000000002252107</td><td>0                   </td><td>6                   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " profit & output & pred & index\\\\\n",
       "\\hline\n",
       "\t 0                    & 0.000003818766799668 & 0                    & 1                   \\\\\n",
       "\t 0                    & 0.000000000203112957 & 0                    & 2                   \\\\\n",
       "\t 0                    & 0.000347295281244442 & 0                    & 3                   \\\\\n",
       "\t 0                    & 0.001790401292964816 & 0                    & 4                   \\\\\n",
       "\t 0                    & 0.999916315078735352 & 1                    & 5                   \\\\\n",
       "\t 0                    & 0.000000000002252107 & 0                    & 6                   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "profit | output | pred | index | \n",
       "|---|---|---|---|---|---|\n",
       "| 0                    | 0.000003818766799668 | 0                    | 1                    | \n",
       "| 0                    | 0.000000000203112957 | 0                    | 2                    | \n",
       "| 0                    | 0.000347295281244442 | 0                    | 3                    | \n",
       "| 0                    | 0.001790401292964816 | 0                    | 4                    | \n",
       "| 0                    | 0.999916315078735352 | 1                    | 5                    | \n",
       "| 0                    | 0.000000000002252107 | 0                    | 6                    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  profit output               pred index\n",
       "1 0      0.000003818766799668 0    1    \n",
       "2 0      0.000000000203112957 0    2    \n",
       "3 0      0.000347295281244442 0    3    \n",
       "4 0      0.001790401292964816 0    4    \n",
       "5 0      0.999916315078735352 1    5    \n",
       "6 0      0.000000000002252107 0    6    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction$pred<-0\n",
    "prediction[which(prediction$output>=0.5),\"pred\"]<-1\n",
    "prediction$index<-seq.int(nrow(prediction))\n",
    "head(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "      0   1\n",
       "  0 565  54\n",
       "  1 179  65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction<-prediction[!is.na(test$gross_2016),]\n",
    "result<-table(prediction$profit,prediction$pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy: 0.730011587485516\"\n",
      "[1] \"Precision: 0.266393442622951\"\n",
      "[1] \"Recall: 0.546218487394958\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0(\"Accuracy: \",(result[1,1]+result[2,2])/sum(result)))\n",
    "print(paste0(\"Precision: \",(result[2,2])/(result[2,2]+result[2,1])))\n",
    "print(paste0(\"Recall: \",(result[2,2])/(result[2,2]+result[1,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this model is more accurate to classify the movies than the regression algorithm from the last section, but not by much. In fact, our model has trouble to classify correctly the profitable movies and tend to overclassify the movie in the non-profitable cathegory. The table above show me that a model who would classify all the movie in the data set as non profitable would have about 55% accuracy which is not that much less than this model. \n",
    "\n",
    "Maybe tuning and simplifying the model will help improve the precision of the model. Let us look at the contribution to the model of each individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nKBLDBAxFYpiAoUgMEzAUiWEC5v8D2BkIo0d0QDgAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance_matrix <- xgb.importance(dimnames(train_xgb_log[,!c(\"profitable\",\"profit\"),with=FALSE])[[2]], model = model_xgb_log)\n",
    "xgb.plot.importance(importance_matrix[1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the 274 variables have little or no influence on the model. In consequence, I will keep only the 20 variables with the most importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_var_log<-c(importance_matrix[1:30,Feature],\"profitable\",\"profit\")\n",
    "train_xgb_log<-train_xgb_log[,names_var_log,with=FALSE]\n",
    "test_xgb_log<-test_xgb_log[,names_var_log,with=FALSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb_log_mat <- xgb.DMatrix(data.matrix(train_xgb_log[,!c(\"profitable\",\"profit\"),with=FALSE]), \n",
    "                                 label=train_xgb_log$profitable,missing=-1)\n",
    "test_xgb_log_mat <- xgb.DMatrix(data.matrix(test_xgb_log[,!c(\"profitable\",\"profit\"),with=FALSE]), \n",
    "                                label=test_xgb_log$profitable,missing=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I do a cross validation to determine which value of the hyperparameter of the algorithm. I started by the ETA.\n",
    "\n",
    "### ETA\n",
    "\n",
    "The eta is a parameter that prevent overfitting by scaling down the weigth of each feature after each iteration. I used a 5 fold cross validation process with 5 round after which the averages of the mean error is calculated for the prediction of the train a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,0.99,0.01)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=i, data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>0.00     </td><td>0.2687690</td><td>0.0030040</td><td>0.2687650</td><td>0.0120120</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0.01     </td><td>0.2106102</td><td>0.0053150</td><td>0.2681410</td><td>0.0089248</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.02     </td><td>0.2093326</td><td>0.0061988</td><td>0.2669412</td><td>0.0091132</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.03     </td><td>0.2079380</td><td>0.0070086</td><td>0.2673060</td><td>0.0083570</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.04     </td><td>0.2055914</td><td>0.0078950</td><td>0.2664192</td><td>0.0101324</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.05     </td><td>0.2041578</td><td>0.0088464</td><td>0.2653764</td><td>0.0110574</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t2 & 0.00      & 0.2687690 & 0.0030040 & 0.2687650 & 0.0120120\\\\\n",
       "\t21 & 0.01      & 0.2106102 & 0.0053150 & 0.2681410 & 0.0089248\\\\\n",
       "\t3 & 0.02      & 0.2093326 & 0.0061988 & 0.2669412 & 0.0091132\\\\\n",
       "\t4 & 0.03      & 0.2079380 & 0.0070086 & 0.2673060 & 0.0083570\\\\\n",
       "\t5 & 0.04      & 0.2055914 & 0.0078950 & 0.2664192 & 0.0101324\\\\\n",
       "\t6 & 0.05      & 0.2041578 & 0.0088464 & 0.2653764 & 0.0110574\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|---|---|---|---|---|\n",
       "| 2 | 0.00      | 0.2687690 | 0.0030040 | 0.2687650 | 0.0120120 | \n",
       "| 21 | 0.01      | 0.2106102 | 0.0053150 | 0.2681410 | 0.0089248 | \n",
       "| 3 | 0.02      | 0.2093326 | 0.0061988 | 0.2669412 | 0.0091132 | \n",
       "| 4 | 0.03      | 0.2079380 | 0.0070086 | 0.2673060 | 0.0083570 | \n",
       "| 5 | 0.04      | 0.2055914 | 0.0078950 | 0.2664192 | 0.0101324 | \n",
       "| 6 | 0.05      | 0.2041578 | 0.0088464 | 0.2653764 | 0.0110574 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "2  0.00  0.2687690        0.0030040       0.2687650       0.0120120     \n",
       "21 0.01  0.2106102        0.0053150       0.2681410       0.0089248     \n",
       "3  0.02  0.2093326        0.0061988       0.2669412       0.0091132     \n",
       "4  0.03  0.2079380        0.0070086       0.2673060       0.0083570     \n",
       "5  0.04  0.2055914        0.0078950       0.2664192       0.0101324     \n",
       "6  0.05  0.2041578        0.0088464       0.2653764       0.0110574     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(xgb_mse_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below show the average mean classification error for the prediction of the test set made with different value of eta from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_eta_mse_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_eta_mse_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the eta parameter',\n",
    "         xaxis = list(title = 'eta', zeroline = TRUE),\n",
    "         yaxis = list(title = 'rmse'))\n",
    "embed_notebook(xgb_log_eta_mse_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_eta_mse_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>45</th><td>0.44     </td><td>0.1779068</td><td>0.0050786</td><td>0.2552106</td><td>0.0093492</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t45 & 0.44      & 0.1779068 & 0.0050786 & 0.2552106 & 0.0093492\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|\n",
       "| 45 | 0.44      | 0.1779068 | 0.0050786 | 0.2552106 | 0.0093492 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "45 0.44  0.1779068        0.0050786       0.2552106       0.0093492     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the value of the parameter eta who minimise the mean error is 0.4 that is the value I'll use for the model.\n",
    "\n",
    "### Alpha\n",
    "\n",
    "Alpha is a regularization term use in the linear version of xgboost. To find the most appropriete value to use in the model, I used the same cross validation process than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,20,0.1)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = i, \n",
    "                                data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_eta_alpha_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_alpha_mse_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the alpha parameter',\n",
    "         xaxis = list(title = 'Alpha', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_alpha_mse_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_eta_alpha_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>54</th><td>5.3      </td><td>0.2010814</td><td>0.0055086</td><td>0.2479624</td><td>0.0113454</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t54 & 5.3       & 0.2010814 & 0.0055086 & 0.2479624 & 0.0113454\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|\n",
       "| 54 | 5.3       | 0.2010814 | 0.0055086 | 0.2479624 | 0.0113454 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "54 5.3   0.2010814        0.0055086       0.2479624       0.0113454     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda\n",
    "\n",
    "Like alpha, lambda is another regularization parameter that prevent overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,10,0.1)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=i,\n",
    "                                data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>0.0      </td><td>0.1972888</td><td>0.0043234</td><td>0.2517156</td><td>0.0126984</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0.1      </td><td>0.1974190</td><td>0.0043068</td><td>0.2515590</td><td>0.0127742</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.2      </td><td>0.1970148</td><td>0.0049518</td><td>0.2509336</td><td>0.0117240</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.3      </td><td>0.1968976</td><td>0.0048442</td><td>0.2513510</td><td>0.0118268</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.4      </td><td>0.1973148</td><td>0.0050204</td><td>0.2505686</td><td>0.0117064</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.5      </td><td>0.1977450</td><td>0.0041752</td><td>0.2505162</td><td>0.0119040</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t2 & 0.0       & 0.1972888 & 0.0043234 & 0.2517156 & 0.0126984\\\\\n",
       "\t21 & 0.1       & 0.1974190 & 0.0043068 & 0.2515590 & 0.0127742\\\\\n",
       "\t3 & 0.2       & 0.1970148 & 0.0049518 & 0.2509336 & 0.0117240\\\\\n",
       "\t4 & 0.3       & 0.1968976 & 0.0048442 & 0.2513510 & 0.0118268\\\\\n",
       "\t5 & 0.4       & 0.1973148 & 0.0050204 & 0.2505686 & 0.0117064\\\\\n",
       "\t6 & 0.5       & 0.1977450 & 0.0041752 & 0.2505162 & 0.0119040\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|---|---|---|---|---|\n",
       "| 2 | 0.0       | 0.1972888 | 0.0043234 | 0.2517156 | 0.0126984 | \n",
       "| 21 | 0.1       | 0.1974190 | 0.0043068 | 0.2515590 | 0.0127742 | \n",
       "| 3 | 0.2       | 0.1970148 | 0.0049518 | 0.2509336 | 0.0117240 | \n",
       "| 4 | 0.3       | 0.1968976 | 0.0048442 | 0.2513510 | 0.0118268 | \n",
       "| 5 | 0.4       | 0.1973148 | 0.0050204 | 0.2505686 | 0.0117064 | \n",
       "| 6 | 0.5       | 0.1977450 | 0.0041752 | 0.2505162 | 0.0119040 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "2  0.0   0.1972888        0.0043234       0.2517156       0.0126984     \n",
       "21 0.1   0.1974190        0.0043068       0.2515590       0.0127742     \n",
       "3  0.2   0.1970148        0.0049518       0.2509336       0.0117240     \n",
       "4  0.3   0.1968976        0.0048442       0.2513510       0.0118268     \n",
       "5  0.4   0.1973148        0.0050204       0.2505686       0.0117064     \n",
       "6  0.5   0.1977450        0.0041752       0.2505162       0.0119040     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(xgb_mse_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_alpha_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_alpha_mse_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the alpha parameter',\n",
    "         xaxis = list(title = 'Alpha', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_alpha_mse_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_alpha_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>14</th><td>1.3      </td><td>0.1988656</td><td>0.0050564</td><td>0.2486386</td><td>0.0145952</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t14 & 1.3       & 0.1988656 & 0.0050564 & 0.2486386 & 0.0145952\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|\n",
       "| 14 | 1.3       | 0.1988656 | 0.0050564 | 0.2486386 | 0.0145952 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "14 1.3   0.1988656        0.0050564       0.2486386       0.0145952     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gamma \n",
    "\n",
    "This parameter is the minimum loss reduction that need to occurs for the partition of a tree. That parameter can take any value greater or equal to 0 and the greater the value, the more conservative the model will be.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,10,0.1)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=5,\n",
    "                                gamma=i,data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_gamma_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_gamma_mse_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the gamma parameter',\n",
    "         xaxis = list(title = 'gamma', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_gamma_mse_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_gamma_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>23</th><td>2.2      </td><td>0.2130214</td><td>0.0051100</td><td>0.2463468</td><td>0.0111840</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>2.4      </td><td>0.2142726</td><td>0.0053868</td><td>0.2463468</td><td>0.0112264</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t23 & 2.2       & 0.2130214 & 0.0051100 & 0.2463468 & 0.0111840\\\\\n",
       "\t25 & 2.4       & 0.2142726 & 0.0053868 & 0.2463468 & 0.0112264\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|---|\n",
       "| 23 | 2.2       | 0.2130214 | 0.0051100 | 0.2463468 | 0.0111840 | \n",
       "| 25 | 2.4       | 0.2142726 | 0.0053868 | 0.2463468 | 0.0112264 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "23 2.2   0.2130214        0.0051100       0.2463468       0.0111840     \n",
       "25 2.4   0.2142726        0.0053868       0.2463468       0.0112264     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As his name indicate that parameter set the maximun depth of each tree. This parameter take value greater or equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(1,50,1)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=5,\n",
    "                                gamma=0.1,max_depth=i,data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_max_depth_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_max_depth_mse_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the max_depth parameter',\n",
    "         xaxis = list(title = 'max_depth', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_max_depth_mse_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_max_depth_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>55       </td><td>0.2380474</td><td>0.00488  </td><td>0.2473398</td><td>0.0086426</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t2 & 55        & 0.2380474 & 0.00488   & 0.2473398 & 0.0086426\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|\n",
       "| 2 | 55        | 0.2380474 | 0.00488   | 0.2473398 | 0.0086426 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  index train.error.mean train.error.std test.error.mean test.error.std\n",
       "2 55    0.2380474        0.00488         0.2473398       0.0086426     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 6 is the defaul value of the parameter max_depth and that value minimise the mean error during the cross validation, I didn't change the defaut value.\n",
    "\n",
    "### min_child_weight\n",
    "\n",
    "This parameter determine the minimun weight that can have a tree after a partition during the creation of the model. Before each partition, the algorithm verify if the resulting child tree would have a weight smaller than that value and if it's the case, he doesn't do the partition. This parameter can take value greater than 0 and the bigger the value the more conservative the model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,150,0.5)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=5,\n",
    "                                gamma=0.1,min_child_weight=i,data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_min_child_weight_expl.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_min_child_weight_expl<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the min_child_weight parameter',\n",
    "         xaxis = list(title = 'min_child_weight', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_min_child_weight_expl,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_min_child_weight_expl\",\".html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there a minimum around min_child_weight=60, so I focus on this area of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(55,70,0.1)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=5,\n",
    "                                gamma=0.1,min_child_weight=i,data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_min_child_weight_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_min_child_weight_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the min_child_weight parameter',\n",
    "         xaxis = list(title = 'min_child_weight', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_min_child_weight_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_min_child_weight_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>55       </td><td>0.2380474</td><td>0.00488  </td><td>0.2473398</td><td>0.0086426</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t2 & 55        & 0.2380474 & 0.00488   & 0.2473398 & 0.0086426\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|\n",
       "| 2 | 55        | 0.2380474 | 0.00488   | 0.2473398 | 0.0086426 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  index train.error.mean train.error.std test.error.mean test.error.std\n",
       "2 55    0.2380474        0.00488         0.2473398       0.0086426     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all those value would minimise the mean classification error, I used min_child_weight=62.\n",
    "\n",
    "### max_delta_step\n",
    "\n",
    "max_delta_step is the maximum variation of the weight that we allow between two iterations of the algorithm. This value could be 0 (no constraint) or greater (more conservative).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,10,0.1)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=5,gamma=0.1,\n",
    "                                min_child_weight=62,max_delta_step=i,data = train_xgb_log_mat,eval_metric= \"error\",\n",
    "                                nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_max_delta_step_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_max_delta_step_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the max_delta_step parameter',\n",
    "         xaxis = list(title = 'max_delta_step', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_max_delta_step_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_max_delta_step_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the default value of the parameter give the minimun mean error, I won't modify this value in the function.\n",
    "\n",
    "### subsample \n",
    "This is the ratio of the sample during the training of the model. This parameter can take value between 0 and 1 (included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_log<-data.frame(index=numeric(0),train.rmse.mean=numeric(0),train.rmse.std=numeric(0),\n",
    "                    test.rmse.mean=numeric(0),test.rmse.std=numeric(0))\n",
    "\n",
    "for (i in seq(0,1,0.01)){\n",
    "    set.seed(383)\n",
    "     model_xgb_log_cv <- xgb.cv(objective= \"binary:logistic\", eta=0.4, alpha = 4.8, lambda=5,,gamma=0.1,\n",
    "                                min_child_weight=62, subsample=i,data = train_xgb_log_mat,\n",
    "                                eval_metric= \"error\",nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_log<-rbind(xgb_mse_log,c(\"index\"=i,lapply( model_xgb_log_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_log_subsample_plot.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_log_subsample_plot<-plot_ly(xgb_mse_log) %>%\n",
    "add_trace(x=~index,y=~test.error.mean, type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Value of the mean error during the cross validation of the subsample parameter',\n",
    "         xaxis = list(title = 'subsample', zeroline = TRUE),\n",
    "         yaxis = list(title = 'Mean error'))\n",
    "embed_notebook(xgb_log_subsample_plot,file=paste0(\"plotlyJupyterHTML/\",\"xgb_log_subsample_plot\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>index</th><th scope=col>train.error.mean</th><th scope=col>train.error.std</th><th scope=col>test.error.mean</th><th scope=col>test.error.std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>96</th><td>0.95     </td><td>0.240563 </td><td>0.005243 </td><td>0.2482244</td><td>0.0108298</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & index & train.error.mean & train.error.std & test.error.mean & test.error.std\\\\\n",
       "\\hline\n",
       "\t96 & 0.95      & 0.240563  & 0.005243  & 0.2482244 & 0.0108298\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | index | train.error.mean | train.error.std | test.error.mean | test.error.std | \n",
       "|---|\n",
       "| 96 | 0.95      | 0.240563  | 0.005243  | 0.2482244 | 0.0108298 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   index train.error.mean train.error.std test.error.mean test.error.std\n",
       "96 0.95  0.240563         0.005243        0.2482244       0.0108298     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse_log[xgb_mse_log$test.error.mean==min(xgb_mse_log$test.error.mean,na.rm=TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I know which value of the hyperparameter to use, I can test the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_tune <- list(     objective= \"binary:logistic\", \n",
    "                        eta=0.4,\n",
    "                        alpha = 4.8, \n",
    "                        lambda=5,\n",
    "                        gamma=0.1, \n",
    "                        min_child_weight=35.5,\n",
    "                        subsample=0.9, \n",
    "                        colsample_bytree=1                \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb_log_tune <- xgb.train(    params              = param_tune, \n",
    "                                    data                = train_xgb_log_mat, \n",
    "                                    nrounds             = 500, \n",
    "                                    eval_metric         = \"error\", \n",
    "                                    missing             =-1,\n",
    "                                    verbose             = 0,\n",
    "                                    maximize            = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction<-data.frame(profit=test_xgb_log$profitable)\n",
    "prediction$output<-NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (rows in split(1:nrow(test_xgb), ceiling((1:nrow(test_xgb))/10000))) {\n",
    "    prediction[rows, \"output\"] <- predict(model_xgb_log_tune, test_xgb_log_mat)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "      0   1\n",
       "  0 553  66\n",
       "  1 175  69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction$pred<-0\n",
    "prediction[which(prediction$output>=0.5),\"pred\"]<-1\n",
    "prediction$index<-seq.int(nrow(prediction))\n",
    "prediction<-prediction[!is.na(test$gross_2016),]\n",
    "\n",
    "result<-table(prediction$profit,prediction$pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy: 0.720741599073001\"\n",
      "[1] \"Precision: 0.282786885245902\"\n",
      "[1] \"Recall: 0.511111111111111\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0(\"Accuracy: \",(result[1,1]+result[2,2])/sum(result)))\n",
    "print(paste0(\"Precision: \",(result[2,2])/(result[2,2]+result[2,1])))\n",
    "print(paste0(\"Recall: \",(result[2,2])/(result[2,2]+result[1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.save(model_xgb_log,fname=\"model_xgb_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "The last algorithm I used is a simple neural network. To do so, I created two new set for training the neural network and testing the model. I choosed to include the continous and genre feature, since a network too complex couldn't be trained in a timely matter by my old computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_nn<-train[,c(cont_var,genre_var),with=FALSE]\n",
    "test_nn<-test[,c(cont_var,genre_var),with=FALSE]\n",
    "\n",
    "train_nn$profitable<-0\n",
    "test_nn$profitable<-0\n",
    "\n",
    "train_nn[which(train_nn$profit>=0),\"profitable\"]<-1\n",
    "test_nn[which(test_nn$profit>=0),\"profitable\"]<-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network I will use won't be able to handle the missing data. In consequence, I delete thos observations from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_nn<-train_nn[complete.cases(train_nn)]\n",
    "test_nn<-test_nn[complete.cases(test_nn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next I normalize the continuous variables and I drop the \"profit\" and \"gross_2016\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (f in cont_var) {\n",
    "  if (max(train_nn[[f]])!=1 | min(train_nn[[f]])!=-1) {\n",
    "    train_nn[[f]] <- scale(train_nn[[f]])\n",
    "    test_nn[[f]]  <- scale(test_nn[[f]])\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nn<-train_nn[,!c(\"profit\",\"gross_2016\"),with=FALSE]\n",
    "test_nn<-test_nn[,!c(\"profit\",\"gross_2016\"),with=FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below I defined the model I want to create with the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n <- names(train_nn)\n",
    "f <- as.formula(paste(\"profitable ~\", paste(n[!n %in% \"profitable\"], collapse = \" + \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profitable ~ duration + director_facebook_likes + actor_3_facebook_likes + \n",
       "    actor_1_facebook_likes + cast_total_facebook_likes + facenumber_in_poster + \n",
       "    actor_2_facebook_likes + budget_2016 + dir_mean_gross + act_1_mean_gross + \n",
       "    act_2_mean_gross + act_3_mean_gross + genres_Action + genres_Adventure + \n",
       "    genres_Animation + genres_Biography + genres_Comedy + genres_Crime + \n",
       "    genres_Documentary + genres_Drama + genres_Family + genres_Fantasy + \n",
       "    genres_Film_Noir + genres_Game_Show + genres_History + genres_Horror + \n",
       "    genres_Music + genres_Musical + genres_Mystery + genres_News + \n",
       "    genres_Reality_TV + genres_Romance + genres_Sci_Fi + genres_Short + \n",
       "    genres_Sport + genres_Thriller + genres_War + genres_Western"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I train the neural network, I must choose the number of hidden layer I'll use, the number of neuron in those layer and the value of the regularization parameter alpha. Since that adding redondant hidden layer give marginal improvement on the neural network, exept in rare occasion or when a lot is added, I chosed one hidden layer. To test how many neuron will be in that layer, I have written a function to easily test multiple value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.neuron<-function(n)\n",
    "{\n",
    "    index <- sample(1:nrow(train_nn),round(0.85*nrow(train_nn)))\n",
    "    train.cv <- train_nn[index,]\n",
    "    cross.val.cv <- train_nn[-index,]\n",
    "    \n",
    "    nn <- neuralnet(f,data=train.cv,hidden=n,algorithm= 'rprop+',learningrate=0.01,\n",
    "                    err.fct = \"sse\",act.fct = \"logistic\",linear.output=FALSE)\n",
    "    pred<-compute(nn, cross.val.cv[,!\"profitable\",with=FALSE])\n",
    "    output<-round(pred$net.result)\n",
    "    result<-sum((cross.val.cv$profitable-output)^2)\n",
    "\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There's 39 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>194</li>\n",
       "\t<li>160</li>\n",
       "\t<li>173</li>\n",
       "\t<li>174</li>\n",
       "\t<li>191</li>\n",
       "\t<li>183</li>\n",
       "\t<li>204</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 194\n",
       "\\item 160\n",
       "\\item 173\n",
       "\\item 174\n",
       "\\item 191\n",
       "\\item 183\n",
       "\\item 204\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 194\n",
       "2. 160\n",
       "3. 173\n",
       "4. 174\n",
       "5. 191\n",
       "6. 183\n",
       "7. 204\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 194 160 173 174 191 183 204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.layer<-NULL\n",
    "for (i in 5*(3:9)){\n",
    "    test.layer<-c(test.layer,test.neuron(i))\n",
    "}\n",
    "test.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.learning.rate<-function(n)\n",
    "{\n",
    "    index <- sample(1:nrow(train_nn),round(0.9*nrow(train_nn)))\n",
    "    train.cv <- train_nn[index,]\n",
    "    cross.val.cv <- train_nn[-index,]\n",
    "    \n",
    "    nn <- neuralnet(f,data=train.cv,hidden=25,algorithm= 'rprop+',learningrate=n,\n",
    "                    err.fct = \"sse\",act.fct = \"logistic\",linear.output=FALSE)\n",
    "    pred<-compute(nn, cross.val.cv[,!\"profitable\",with=FALSE])\n",
    "    output<-round(pred$net.result)\n",
    "    result<-sum((cross.val.cv$profitable-output)^2)\n",
    "    \n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>129</li>\n",
       "\t<li>113</li>\n",
       "\t<li>120</li>\n",
       "\t<li>124</li>\n",
       "\t<li>119</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 129\n",
       "\\item 113\n",
       "\\item 120\n",
       "\\item 124\n",
       "\\item 119\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 129\n",
       "2. 113\n",
       "3. 120\n",
       "4. 124\n",
       "5. 119\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 129 113 120 124 119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.lr<-NULL\n",
    "learning.rate<-c(0.01,0.007,0.005,0.002,0.001)\n",
    "for (i in (learning.rate)){\n",
    "    test.lr<-c(test.lr,test.learning.rate(i))\n",
    "}\n",
    "test.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "initial_weight <- runif(1240, -(1/sqrt(39)),(1/sqrt(39)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn <- neuralnet(f,data=train_nn,hidden=30,algorithm= 'rprop+',stepmax=10000000,startweights =initial_weight,\n",
    "                    err.fct = \"sse\",act.fct = \"logistic\",linear.output=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "289"
      ],
      "text/latex": [
       "289"
      ],
      "text/markdown": [
       "289"
      ],
      "text/plain": [
       "[1] 289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   output\n",
       "      0   1\n",
       "  0 195 165\n",
       "  1 124 209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy: 0.582972582972583\"\n"
     ]
    }
   ],
   "source": [
    "pred<-compute(nn, test_nn[,!\"profitable\",with=FALSE])\n",
    "    output<-round(pred$net.result)\n",
    "    sse<-sum((test_nn$profitable-output)^2)\n",
    "sse\n",
    "result<-table(test_nn$profitable,output)\n",
    "result\n",
    "print(paste0(\"Accuracy: \",(result[1,1]+result[2,2])/sum(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse<-data.frame(index=as.numeric(0),train.rmse.mean=as.numeric(0),train.rmse.std=as.numeric(0),\n",
    "                    test.rmse.mean=as.numeric(0),test.rmse.std=as.numeric(0))\n",
    "\n",
    "for (i in seq(0.1,0.9,0.01)){\n",
    "    set.seed(383)\n",
    "    model_xgb_cv <- xgb.cv(params=param, eta=i, data = train_xgb_matrix, nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse<-rbind(xgb_mse,c(\"index\"=i,lapply(model_xgb_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_mse1.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse1<-plot_ly(xgb_mse) %>%\n",
    "add_trace(x=~index,y=~test.rmse.mean, name = 'trace 0', type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Trend line of the proportion ofmovie\\'s color in the IMDB data set over the year',\n",
    "         xaxis = list(title = 'eta', zeroline = TRUE),\n",
    "         yaxis = list(title = 'rmse'))\n",
    "embed_notebook(xgb_mse1,file=paste0(\"plotlyJupyterHTML/\",\"xgb_mse1\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb_1_tune <- xgb.train(   params          = param, \n",
    "                    data                  = train_xgb_matrix, \n",
    "                    eta                   = 0.34,\n",
    "                    nrounds               = 500, \n",
    "                    verbose               = 0, \n",
    "                    early_stopping_rounds = 20,\n",
    "                    missing               = -1,\n",
    "                    maximize              = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "95464240.9596377"
      ],
      "text/latex": [
       "95464240.9596377"
      ],
      "text/markdown": [
       "95464240.9596377"
      ],
      "text/plain": [
       "[1] 95464241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred<-predict(model_xgb_1_tune,test_xgb_matrix)\n",
    "scaleList <- list(scale = attr(train_xgb$gross_2016, \"scaled:scale\"),\n",
    "    center = attr(train_xgb$gross_2016, \"scaled:center\"))\n",
    "\n",
    "pred_unscale <- pred * scaleList$scale + scaleList$center\n",
    "error<-pred_unscale-test_xgb$gross_2016\n",
    "rmse(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (f in variable_names) {\n",
    "  if (class(train_xgb[[f]])==\"character\") {\n",
    "    levels <- unique(c(train_xgb[[f]],cross_val_xgb[[f]],test_xgb[[f]]))\n",
    "    train_xgb[[f]] <- as.numeric(factor(train_xgb[[f]], levels=levels))\n",
    "    cross_val_xgb[[f]] <- as.numeric(factor(cross_val_xgb[[f]], levels=levels))\n",
    "    test_xgb[[f]]  <- as.numeric(factor(test_xgb[[f]],  levels=levels))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_mse_2<-data.frame(index=as.numeric(0),train.rmse.mean=as.numeric(0),train.rmse.std=as.numeric(0),\n",
    "                    test.rmse.mean=as.numeric(0),test.rmse.std=as.numeric(0))\n",
    "\n",
    "for (i in seq(0.1,0.9,0.01)){\n",
    "    set.seed(383)\n",
    "     model_xgb_cv <- xgb.cv(params=param, eta=i, data = train_xgb_matrix, nfold = 5, nrounds = 5, missing=-1,verbose= 0)\n",
    "    xgb_mse_2<-rbind(xgb_mse_2,c(\"index\"=i,lapply( model_xgb_cv,function(x) mean(x))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"plotlyJupyterHTML/xgb_mse2.html\" width=\"100%\" height=\"400\" id=\"igraph\" scrolling=\"no\" seamless=\"seamless\" frameBorder=\"0\"> </iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_mse2<-plot_ly(xgb_mse_2) %>%\n",
    "add_trace(x=~index,y=~test.rmse.mean, name = 'trace 0', type = 'scatter',mode = 'lines+markers' )%>%\n",
    "layout(title = 'Trend line of the proportion ofmovie\\'s color in the IMDB data set over the year',\n",
    "         xaxis = list(title = 'eta', zeroline = TRUE),\n",
    "         yaxis = list(title = 'rmse'))\n",
    "embed_notebook(xgb_mse2,file=paste0(\"plotlyJupyterHTML/\",\"xgb_mse2\",\".html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(383)\n",
    "model_xgb_2_tune <- xgb.train(   params          = param, \n",
    "                    data                  = train_xgb_matrix, \n",
    "                    eta                   = 0.25,\n",
    "                    nrounds               = 500, # changed from 300\n",
    "                    verbose               = 0, \n",
    "                    early_stopping_rounds = 20,\n",
    "                    missing               = -1,\n",
    "                    maximize              = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83849993.6021591"
      ],
      "text/latex": [
       "83849993.6021591"
      ],
      "text/markdown": [
       "83849993.6021591"
      ],
      "text/plain": [
       "[1] 83849994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred<-predict(model_xgb_2_tune,test_xgb_matrix)\n",
    "scaleList <- list(scale = attr(train_xgb$gross_2016, \"scaled:scale\"),\n",
    "    center = attr(train_xgb$gross_2016, \"scaled:center\"))\n",
    "\n",
    "pred_unscale <- pred * scaleList$scale + scaleList$center\n",
    "error<-pred_unscale-test_xgb$gross_2016\n",
    "rmse(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# XGBoost tree\n",
    "\n",
    "Since the XGBoost algorithm give good result, I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 4 class: higly profitable(3), profitable(2), non-profitable(1), higly non-profitable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xgb$profitable<-0\n",
    "test_xgb$profitable<-0\n",
    "\n",
    "train_xgb[which(train_xgb$profit>=0),\"profitable\"]<-1 \n",
    "test_xgb[which(test_xgb$profit>=0),\"profitable\"]<-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tree_mat <- xgb.DMatrix(data.matrix(train_xgb[,!c(\"profitable\",\"profit\"),with=FALSE]), \n",
    "                              label=train_xgb$profitable,missing=-1)\n",
    "test_tree_mat <- xgb.DMatrix(data.matrix(test_xgb[,!c(\"profitable\",\"profit\"),with=FALSE]), \n",
    "                             label=test_xgb$profitable,missing=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist <- list(eval = test_tree_mat , train=train_tree_mat )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param <- list(  objective           = \"multi:softmax\", \n",
    "                num_class           = 2,\n",
    "                eta                 = 0.01,\n",
    "                max_depth           = 14,  \n",
    "                #subsample           = 0.6,\n",
    "                #colsample_bytree    = 0.6,\n",
    "                eval_metric         = \"merror\"\n",
    "                # alpha = 0.0001, \n",
    "                # lambda = 1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"'early.stop.round' is deprecated.\n",
      "Use 'early_stopping_rounds' instead.\n",
      "See help(\"Deprecated\") and help(\"xgboost-deprecated\").\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 934 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 934 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[1]\teval-merror:0.341641\ttrain-merror:0.081214 \n",
      "Multiple eval metrics are present. Will use train_merror for early stopping.\n",
      "Will train until train_merror hasn't improved in 20 rounds.\n",
      "\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 874 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 874 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[2]\teval-merror:0.323988\ttrain-merror:0.036845 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 798 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 798 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[3]\teval-merror:0.327103\ttrain-merror:0.038921 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 854 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 854 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[4]\teval-merror:0.325026\ttrain-merror:0.034769 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 864 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 864 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[5]\teval-merror:0.315680\ttrain-merror:0.037104 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 794 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 794 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[6]\teval-merror:0.328141\ttrain-merror:0.037623 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 870 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 870 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[7]\teval-merror:0.314642\ttrain-merror:0.038661 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 866 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 866 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[8]\teval-merror:0.323988\ttrain-merror:0.038661 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 784 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 784 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[9]\teval-merror:0.313603\ttrain-merror:0.038402 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 880 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 880 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10]\teval-merror:0.319834\ttrain-merror:0.037883 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 868 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 868 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[11]\teval-merror:0.321911\ttrain-merror:0.038921 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 776 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 776 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[12]\teval-merror:0.318795\ttrain-merror:0.036845 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 880 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 880 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[13]\teval-merror:0.317757\ttrain-merror:0.037104 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 884 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 884 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[14]\teval-merror:0.317757\ttrain-merror:0.036326 \n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 788 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:18] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 788 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[15]\teval-merror:0.316719\ttrain-merror:0.035807 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 870 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 870 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[16]\teval-merror:0.318795\ttrain-merror:0.034250 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 762 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 762 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[17]\teval-merror:0.314642\ttrain-merror:0.035547 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 880 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 880 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[18]\teval-merror:0.314642\ttrain-merror:0.033472 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 780 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 780 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[19]\teval-merror:0.316719\ttrain-merror:0.032953 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 870 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 870 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[20]\teval-merror:0.315680\ttrain-merror:0.031396 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 788 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 788 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[21]\teval-merror:0.314642\ttrain-merror:0.031136 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 814 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 814 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[22]\teval-merror:0.317757\ttrain-merror:0.028801 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 798 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 798 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[23]\teval-merror:0.315680\ttrain-merror:0.029580 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 878 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 878 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[24]\teval-merror:0.318795\ttrain-merror:0.029061 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 826 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 826 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[25]\teval-merror:0.315680\ttrain-merror:0.029061 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[26]\teval-merror:0.316719\ttrain-merror:0.027504 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 806 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 806 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[27]\teval-merror:0.314642\ttrain-merror:0.027244 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 864 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 864 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[28]\teval-merror:0.317757\ttrain-merror:0.025428 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 806 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 806 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[29]\teval-merror:0.314642\ttrain-merror:0.025428 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 758 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 758 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[30]\teval-merror:0.316719\ttrain-merror:0.023871 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[31]\teval-merror:0.312565\ttrain-merror:0.023612 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 854 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 854 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[32]\teval-merror:0.306334\ttrain-merror:0.024131 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 768 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 768 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[33]\teval-merror:0.308411\ttrain-merror:0.023612 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 842 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 842 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[34]\teval-merror:0.304258\ttrain-merror:0.023352 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 840 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 840 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[35]\teval-merror:0.307373\ttrain-merror:0.023352 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[36]\teval-merror:0.308411\ttrain-merror:0.022833 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 782 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 782 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[37]\teval-merror:0.305296\ttrain-merror:0.021277 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 830 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 830 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[38]\teval-merror:0.307373\ttrain-merror:0.021017 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 778 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 778 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[39]\teval-merror:0.302181\ttrain-merror:0.020239 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[40]\teval-merror:0.300104\ttrain-merror:0.019201 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 846 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 846 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[41]\teval-merror:0.300104\ttrain-merror:0.019201 \n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 836 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:19] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 836 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[42]\teval-merror:0.301142\ttrain-merror:0.018682 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 804 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 804 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[43]\teval-merror:0.303219\ttrain-merror:0.018682 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 834 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 834 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[44]\teval-merror:0.305296\ttrain-merror:0.018941 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 844 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 844 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[45]\teval-merror:0.302181\ttrain-merror:0.018163 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 798 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 798 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[46]\teval-merror:0.305296\ttrain-merror:0.017644 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[47]\teval-merror:0.304258\ttrain-merror:0.016866 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 792 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 792 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[48]\teval-merror:0.301142\ttrain-merror:0.017125 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 786 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 786 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[49]\teval-merror:0.301142\ttrain-merror:0.016866 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 844 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 844 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[50]\teval-merror:0.300104\ttrain-merror:0.016606 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 790 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 790 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[51]\teval-merror:0.301142\ttrain-merror:0.015828 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 752 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 752 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[52]\teval-merror:0.302181\ttrain-merror:0.015049 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 842 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 842 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[53]\teval-merror:0.303219\ttrain-merror:0.014530 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 756 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 756 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[54]\teval-merror:0.303219\ttrain-merror:0.014271 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 788 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 788 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[55]\teval-merror:0.301142\ttrain-merror:0.014271 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 762 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 762 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[56]\teval-merror:0.303219\ttrain-merror:0.014011 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 752 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 752 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[57]\teval-merror:0.300104\ttrain-merror:0.013752 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 808 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 808 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[58]\teval-merror:0.296989\ttrain-merror:0.014011 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 752 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 752 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[59]\teval-merror:0.301142\ttrain-merror:0.014271 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 764 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 764 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[60]\teval-merror:0.298027\ttrain-merror:0.014790 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 784 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 784 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[61]\teval-merror:0.302181\ttrain-merror:0.014011 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 778 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 778 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[62]\teval-merror:0.303219\ttrain-merror:0.013752 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 794 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 794 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[63]\teval-merror:0.305296\ttrain-merror:0.013752 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 796 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 796 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[64]\teval-merror:0.304258\ttrain-merror:0.013233 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 810 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 810 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[65]\teval-merror:0.305296\ttrain-merror:0.013492 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 820 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 820 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[66]\teval-merror:0.304258\ttrain-merror:0.014271 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 766 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 766 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[67]\teval-merror:0.300104\ttrain-merror:0.013752 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 746 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 746 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[68]\teval-merror:0.303219\ttrain-merror:0.013752 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 810 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 810 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[69]\teval-merror:0.301142\ttrain-merror:0.013752 \n",
      "[10:25:20] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 768 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 768 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[70]\teval-merror:0.302181\ttrain-merror:0.013752 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 782 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 782 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[71]\teval-merror:0.301142\ttrain-merror:0.013492 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 808 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 808 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[72]\teval-merror:0.304258\ttrain-merror:0.013492 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 806 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 806 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[73]\teval-merror:0.303219\ttrain-merror:0.013492 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 852 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 852 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[74]\teval-merror:0.303219\ttrain-merror:0.012714 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 774 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 774 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[75]\teval-merror:0.301142\ttrain-merror:0.013233 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 844 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 844 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[76]\teval-merror:0.302181\ttrain-merror:0.012195 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 778 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 778 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[77]\teval-merror:0.302181\ttrain-merror:0.012974 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 770 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 770 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[78]\teval-merror:0.302181\ttrain-merror:0.012455 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 826 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 826 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[79]\teval-merror:0.301142\ttrain-merror:0.012195 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 816 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 816 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[80]\teval-merror:0.298027\ttrain-merror:0.012455 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 820 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 820 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[81]\teval-merror:0.298027\ttrain-merror:0.012195 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 812 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 812 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[82]\teval-merror:0.296989\ttrain-merror:0.011936 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[83]\teval-merror:0.295950\ttrain-merror:0.011936 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 800 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[84]\teval-merror:0.294912\ttrain-merror:0.011676 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 736 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 736 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[85]\teval-merror:0.294912\ttrain-merror:0.011936 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 812 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 812 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[86]\teval-merror:0.299065\ttrain-merror:0.011676 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 774 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 774 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[87]\teval-merror:0.294912\ttrain-merror:0.011417 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 746 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 746 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[88]\teval-merror:0.294912\ttrain-merror:0.011676 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 754 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 754 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[89]\teval-merror:0.294912\ttrain-merror:0.011417 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 738 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 738 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[90]\teval-merror:0.295950\ttrain-merror:0.011417 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 828 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[91]\teval-merror:0.295950\ttrain-merror:0.010898 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 784 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 784 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[92]\teval-merror:0.298027\ttrain-merror:0.010898 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 764 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 764 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[93]\teval-merror:0.296989\ttrain-merror:0.010638 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 780 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 780 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[94]\teval-merror:0.296989\ttrain-merror:0.010638 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 750 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 750 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[95]\teval-merror:0.295950\ttrain-merror:0.010638 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 624 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 624 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[96]\teval-merror:0.294912\ttrain-merror:0.010379 \n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 626 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:21] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 626 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[97]\teval-merror:0.293873\ttrain-merror:0.010119 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 620 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 620 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[98]\teval-merror:0.291796\ttrain-merror:0.009860 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 614 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 614 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[99]\teval-merror:0.291796\ttrain-merror:0.010119 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 614 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 614 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[100]\teval-merror:0.292835\ttrain-merror:0.009860 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 618 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 618 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[101]\teval-merror:0.291796\ttrain-merror:0.009860 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 612 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 612 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[102]\teval-merror:0.292835\ttrain-merror:0.009600 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[103]\teval-merror:0.291796\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 744 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 744 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[104]\teval-merror:0.292835\ttrain-merror:0.009081 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 632 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 632 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[105]\teval-merror:0.291796\ttrain-merror:0.009081 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[106]\teval-merror:0.290758\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 628 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 628 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[107]\teval-merror:0.291796\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[108]\teval-merror:0.292835\ttrain-merror:0.009600 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 632 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 632 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[109]\teval-merror:0.293873\ttrain-merror:0.009600 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[110]\teval-merror:0.293873\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[111]\teval-merror:0.294912\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[112]\teval-merror:0.295950\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[113]\teval-merror:0.298027\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[114]\teval-merror:0.294912\ttrain-merror:0.009341 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 642 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 642 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[115]\teval-merror:0.295950\ttrain-merror:0.009081 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[116]\teval-merror:0.294912\ttrain-merror:0.009081 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 720 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 720 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[117]\teval-merror:0.295950\ttrain-merror:0.008563 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 616 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 616 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[118]\teval-merror:0.296989\ttrain-merror:0.008303 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[119]\teval-merror:0.295950\ttrain-merror:0.008303 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 718 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 718 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[120]\teval-merror:0.296989\ttrain-merror:0.008303 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[121]\teval-merror:0.298027\ttrain-merror:0.008303 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[122]\teval-merror:0.300104\ttrain-merror:0.008303 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 730 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 730 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[123]\teval-merror:0.301142\ttrain-merror:0.008044 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 720 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 720 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[124]\teval-merror:0.300104\ttrain-merror:0.008044 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 646 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 646 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[125]\teval-merror:0.300104\ttrain-merror:0.008044 \n",
      "[10:25:22] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 692 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 692 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[126]\teval-merror:0.299065\ttrain-merror:0.007784 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[127]\teval-merror:0.299065\ttrain-merror:0.007784 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[128]\teval-merror:0.299065\ttrain-merror:0.007525 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 710 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 710 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[129]\teval-merror:0.298027\ttrain-merror:0.007525 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[130]\teval-merror:0.296989\ttrain-merror:0.007784 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 706 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 706 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[131]\teval-merror:0.296989\ttrain-merror:0.007525 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 638 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[132]\teval-merror:0.296989\ttrain-merror:0.006746 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 640 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 640 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[133]\teval-merror:0.298027\ttrain-merror:0.006487 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 760 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 760 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[134]\teval-merror:0.295950\ttrain-merror:0.006487 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 662 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 662 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[135]\teval-merror:0.295950\ttrain-merror:0.006227 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 690 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 690 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[136]\teval-merror:0.294912\ttrain-merror:0.006227 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 682 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 682 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[137]\teval-merror:0.295950\ttrain-merror:0.006227 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 702 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 702 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[138]\teval-merror:0.294912\ttrain-merror:0.005708 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 660 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 660 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[139]\teval-merror:0.295950\ttrain-merror:0.005708 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 682 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 682 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[140]\teval-merror:0.296989\ttrain-merror:0.005708 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 682 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 682 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[141]\teval-merror:0.293873\ttrain-merror:0.005708 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 654 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 654 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[142]\teval-merror:0.293873\ttrain-merror:0.005708 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 710 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 710 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[143]\teval-merror:0.294912\ttrain-merror:0.005449 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 636 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 636 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[144]\teval-merror:0.291796\ttrain-merror:0.005449 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 672 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 672 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[145]\teval-merror:0.291796\ttrain-merror:0.005449 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 702 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 702 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[146]\teval-merror:0.292835\ttrain-merror:0.005189 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 624 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 624 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[147]\teval-merror:0.292835\ttrain-merror:0.005189 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 722 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 722 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[148]\teval-merror:0.293873\ttrain-merror:0.004930 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 610 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 610 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[149]\teval-merror:0.294912\ttrain-merror:0.004670 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 684 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 684 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[150]\teval-merror:0.292835\ttrain-merror:0.004930 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 712 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 712 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[151]\teval-merror:0.290758\ttrain-merror:0.004930 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 650 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 650 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[152]\teval-merror:0.292835\ttrain-merror:0.004670 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 632 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 632 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[153]\teval-merror:0.293873\ttrain-merror:0.004670 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 652 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 652 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[154]\teval-merror:0.295950\ttrain-merror:0.004670 \n",
      "[10:25:23] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 634 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 634 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[155]\teval-merror:0.295950\ttrain-merror:0.004411 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 630 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[156]\teval-merror:0.295950\ttrain-merror:0.004411 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 660 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 660 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[157]\teval-merror:0.295950\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 634 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 634 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[158]\teval-merror:0.295950\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 634 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 634 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[159]\teval-merror:0.295950\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 628 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 628 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[160]\teval-merror:0.295950\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 694 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 694 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[161]\teval-merror:0.296989\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 686 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 686 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[162]\teval-merror:0.296989\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 658 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 658 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[163]\teval-merror:0.298027\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 602 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 602 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[164]\teval-merror:0.298027\ttrain-merror:0.003892 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 674 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 674 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[165]\teval-merror:0.298027\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 694 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 694 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[166]\teval-merror:0.296989\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 628 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 628 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[167]\teval-merror:0.300104\ttrain-merror:0.004152 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 564 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 564 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[168]\teval-merror:0.299065\ttrain-merror:0.003892 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 564 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 564 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[169]\teval-merror:0.298027\ttrain-merror:0.003892 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 566 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 566 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[170]\teval-merror:0.298027\ttrain-merror:0.003892 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 610 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 610 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[171]\teval-merror:0.298027\ttrain-merror:0.003892 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[172]\teval-merror:0.295950\ttrain-merror:0.003633 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 660 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 660 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[173]\teval-merror:0.298027\ttrain-merror:0.003633 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 612 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 612 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[174]\teval-merror:0.295950\ttrain-merror:0.003633 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 538 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 538 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[175]\teval-merror:0.295950\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 620 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 620 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[176]\teval-merror:0.293873\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[177]\teval-merror:0.291796\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 698 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 698 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[178]\teval-merror:0.292835\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 622 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[179]\teval-merror:0.291796\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 530 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 530 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[180]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 528 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 528 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[181]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 664 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 664 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[182]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 596 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 596 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[183]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 518 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:24] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 518 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[184]\teval-merror:0.290758\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 570 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 570 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[185]\teval-merror:0.290758\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 606 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 606 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[186]\teval-merror:0.288681\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 602 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 602 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[187]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 568 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 568 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[188]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 594 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 594 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[189]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 514 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 514 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[190]\teval-merror:0.287643\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 572 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 572 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[191]\teval-merror:0.289720\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 684 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 684 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[192]\teval-merror:0.288681\ttrain-merror:0.003373 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 604 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 604 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[193]\teval-merror:0.287643\ttrain-merror:0.003114 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 566 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 566 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[194]\teval-merror:0.287643\ttrain-merror:0.003114 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 596 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 596 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[195]\teval-merror:0.285566\ttrain-merror:0.003114 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 598 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 598 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[196]\teval-merror:0.283489\ttrain-merror:0.003114 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 540 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 540 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[197]\teval-merror:0.283489\ttrain-merror:0.002854 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 530 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 530 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[198]\teval-merror:0.284528\ttrain-merror:0.002854 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 542 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 542 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[199]\teval-merror:0.284528\ttrain-merror:0.002854 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 678 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 678 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[200]\teval-merror:0.283489\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 576 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 576 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[201]\teval-merror:0.283489\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 574 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 574 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[202]\teval-merror:0.283489\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 570 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 570 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[203]\teval-merror:0.284528\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 584 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 584 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[204]\teval-merror:0.283489\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 556 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 556 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[205]\teval-merror:0.284528\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 514 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 514 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[206]\teval-merror:0.285566\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 504 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 504 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[207]\teval-merror:0.286604\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 672 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 672 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[208]\teval-merror:0.287643\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 554 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 554 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[209]\teval-merror:0.287643\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 530 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 530 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[210]\teval-merror:0.287643\ttrain-merror:0.002595 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 502 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 502 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[211]\teval-merror:0.287643\ttrain-merror:0.002335 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 496 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 496 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[212]\teval-merror:0.287643\ttrain-merror:0.002335 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 506 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 506 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[213]\teval-merror:0.288681\ttrain-merror:0.002335 \n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 462 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:25] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 462 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[214]\teval-merror:0.288681\ttrain-merror:0.002335 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 512 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 512 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[215]\teval-merror:0.288681\ttrain-merror:0.002335 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 532 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 532 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[216]\teval-merror:0.288681\ttrain-merror:0.002076 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 654 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 654 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[217]\teval-merror:0.291796\ttrain-merror:0.002076 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 652 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 652 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[218]\teval-merror:0.291796\ttrain-merror:0.001816 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 508 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 508 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[219]\teval-merror:0.291796\ttrain-merror:0.001816 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 522 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 522 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[220]\teval-merror:0.291796\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 490 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 490 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[221]\teval-merror:0.290758\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 658 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 658 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[222]\teval-merror:0.289720\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 704 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[223]\teval-merror:0.289720\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 596 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 596 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[224]\teval-merror:0.288681\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 464 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 464 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[225]\teval-merror:0.288681\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 464 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 464 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[226]\teval-merror:0.287643\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 510 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 510 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[227]\teval-merror:0.287643\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 492 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 492 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[228]\teval-merror:0.286604\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[229]\teval-merror:0.286604\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 450 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 450 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[230]\teval-merror:0.286604\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 666 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 666 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[231]\teval-merror:0.287643\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 446 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 446 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[232]\teval-merror:0.286604\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 480 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 480 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[233]\teval-merror:0.288681\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 454 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 454 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[234]\teval-merror:0.287643\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 516 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 516 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[235]\teval-merror:0.287643\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 648 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[236]\teval-merror:0.286604\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 460 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 460 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[237]\teval-merror:0.285566\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 472 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 472 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[238]\teval-merror:0.285566\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 472 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 472 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[239]\teval-merror:0.285566\ttrain-merror:0.001297 \n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 460 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[10:25:26] amalgamation/../src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 460 extra nodes, 0 pruned nodes, max_depth=14\n",
      "[240]\teval-merror:0.285566\ttrain-merror:0.001297 \n",
      "Stopping. Best iteration:\n",
      "[220]\teval-merror:0.291796\ttrain-merror:0.001297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set.seed(383)\n",
    "model_xgb_tree <- xgb.train(   params        = param, \n",
    "                    data                     = train_tree_mat, \n",
    "                    nrounds                  = 500, # changed from 300\n",
    "                    verbose                  = 2, \n",
    "                    early_stopping_rounds    = 20,\n",
    "                    watchlist                = watchlist,\n",
    "                    missing                  =NA,\n",
    "                    maximize                 = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-merror:0.081003+0.005405\ttest-merror:0.314113+0.075735 \n",
      "[2]\ttrain-merror:0.069269+0.008364\ttest-merror:0.313650+0.077467 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "##### xgb.cv 100-folds\n",
       " iter train_merror_mean train_merror_std test_merror_mean test_merror_std\n",
       "    1        0.08100288      0.005405426        0.3141132      0.07573513\n",
       "    2        0.06926909      0.008364049        0.3136498      0.07746738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.xgb.tree.cv<- xgb.cv(data = train_tree_mat,params=param, nfold = 100,nrounds = 2, missing=-1)\n",
    "model.xgb.tree.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction<-data.frame(profit=test_xgb$profitable)\n",
    "prediction$output<-NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (rows in split(1:nrow(test_xgb), ceiling((1:nrow(test_xgb))/10000))) {\n",
    "    prediction[rows, \"output\"] <- predict(model_xgb_tree, test_tree_mat)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>profit</th><th scope=col>output</th><th scope=col>index</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>2</td></tr>\n",
       "\t<tr><td>0</td><td>1</td><td>3</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>4</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>5</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " profit & output & index\\\\\n",
       "\\hline\n",
       "\t 0 & 0 & 1\\\\\n",
       "\t 0 & 0 & 2\\\\\n",
       "\t 0 & 1 & 3\\\\\n",
       "\t 1 & 0 & 4\\\\\n",
       "\t 0 & 0 & 5\\\\\n",
       "\t 0 & 0 & 6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "profit | output | index | \n",
       "|---|---|---|---|---|---|\n",
       "| 0 | 0 | 1 | \n",
       "| 0 | 0 | 2 | \n",
       "| 0 | 1 | 3 | \n",
       "| 1 | 0 | 4 | \n",
       "| 0 | 0 | 5 | \n",
       "| 0 | 0 | 6 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  profit output index\n",
       "1 0      0      1    \n",
       "2 0      0      2    \n",
       "3 0      1      3    \n",
       "4 1      0      4    \n",
       "5 0      0      5    \n",
       "6 0      0      6    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction$index<-seq.int(nrow(prediction))\n",
    "head(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "      0   1\n",
       "  0 620  87\n",
       "  1 194  62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result<-table(prediction$profit,prediction$output)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy: 0.708203530633437\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0(\"Accuracy: \",(result[1,1]+result[2,2])/sum(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAXFxcqKio8PDxN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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance_matrix <- xgb.importance(dimnames(train_xgb)[[2]], model = model_xgb_tree)\n",
    "xgb.plot.importance(importance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.save(model_xgb_tree,fname=\"model_xgb_tree\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
