{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error metrics\n",
    "\n",
    "There was a time where statistician had to manually crunch number when they wanted to fit their data to a model. Since this process was so long, those statisticians usually did a lot of preliminary work\n",
    "researching other model who worked in the past or looking for studies in other scientific field like psychology or sociology who can influence their model with the goal to maximize their chance to make a relevant model.\n",
    " Then they would create a model and an alternative model and choose the one which seem more efficient.\n",
    "\n",
    "Now that even an average computer give us incredible computing power, it's easy to make multiple models and choose the one that best fit the data. Even though it is better to have good\n",
    "prior knowledge of the process you are trying to analyze and of other model used in the past, coming to a conclusion using mostly only the data help you avoid bias and help you create better models.\n",
    "\n",
    "In this set of exercises, we'll see how to apply the most used error metrics on your models with the intention to rate them and choose the one that is the more appropriate for the situation.\n",
    "Most of those errors metrics are not part of any R package, in consequence you have to apply the equation I give you on your data. Personally, I preferred to write a function which I can easily\n",
    "use on everyone of my models, but there's many ways to code those equations. If your code is different from the one in the solution, feel free to post your code in the comments.\n",
    "\n",
    "\n",
    "The full exercises set is available <a href=\"http://www.r-exercises.com/2017/05/31/evaluate-your-model-with-r-exercises/\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Exercise 1</strong>\n",
    "We start by looking at error metrics we can use for regression model. For linear regression problem, the more used metrics are the coefficient of determination <i>R</i><sup>2</sup> which show what percentage of\n",
    "variance is explained by the model and the adjusted <i>R</i><sup>2</sup> which penalize model who use variables that doesn't have an effective contribution to the model\n",
    "(see <a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2\">this page</a> for more details). Load the <code>attitude</code> data set from the package of the same name and make three\n",
    "linear models with the goal to explain the <code>rating</code> variable. The first one use all the variables from the dataset, the second one use the variable <code>complaints</code>, <code>privileges</code>,\n",
    "<code>learning</code> and <code>advance</code> as independent variables and the third one use only the <code>complaints</code>, <code>learning</code> and <code>advance</code> variables. Then use the <code>summary()</code>\n",
    "function to print <i>R</i><sup>2</sup> and the adjusted <i>R</i><sup>2</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>rating</th><th scope=col>complaints</th><th scope=col>privileges</th><th scope=col>learning</th><th scope=col>raises</th><th scope=col>critical</th><th scope=col>advance</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>43</td><td>51</td><td>30</td><td>39</td><td>61</td><td>92</td><td>45</td></tr>\n",
       "\t<tr><td>63</td><td>64</td><td>51</td><td>54</td><td>63</td><td>73</td><td>47</td></tr>\n",
       "\t<tr><td>71</td><td>70</td><td>68</td><td>69</td><td>76</td><td>86</td><td>48</td></tr>\n",
       "\t<tr><td>61</td><td>63</td><td>45</td><td>47</td><td>54</td><td>84</td><td>35</td></tr>\n",
       "\t<tr><td>81</td><td>78</td><td>56</td><td>66</td><td>71</td><td>83</td><td>47</td></tr>\n",
       "\t<tr><td>43</td><td>55</td><td>49</td><td>44</td><td>54</td><td>49</td><td>34</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " rating & complaints & privileges & learning & raises & critical & advance\\\\\n",
       "\\hline\n",
       "\t 43 & 51 & 30 & 39 & 61 & 92 & 45\\\\\n",
       "\t 63 & 64 & 51 & 54 & 63 & 73 & 47\\\\\n",
       "\t 71 & 70 & 68 & 69 & 76 & 86 & 48\\\\\n",
       "\t 61 & 63 & 45 & 47 & 54 & 84 & 35\\\\\n",
       "\t 81 & 78 & 56 & 66 & 71 & 83 & 47\\\\\n",
       "\t 43 & 55 & 49 & 44 & 54 & 49 & 34\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "rating | complaints | privileges | learning | raises | critical | advance | \n",
       "|---|---|---|---|---|---|\n",
       "| 43 | 51 | 30 | 39 | 61 | 92 | 45 | \n",
       "| 63 | 64 | 51 | 54 | 63 | 73 | 47 | \n",
       "| 71 | 70 | 68 | 69 | 76 | 86 | 48 | \n",
       "| 61 | 63 | 45 | 47 | 54 | 84 | 35 | \n",
       "| 81 | 78 | 56 | 66 | 71 | 83 | 47 | \n",
       "| 43 | 55 | 49 | 44 | 54 | 49 | 34 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  rating complaints privileges learning raises critical advance\n",
       "1 43     51         30         39       61     92       45     \n",
       "2 63     64         51         54       63     73       47     \n",
       "3 71     70         68         69       76     86       48     \n",
       "4 61     63         45         47       54     84       35     \n",
       "5 81     78         56         66       71     83       47     \n",
       "6 43     55         49         44       54     49       34     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = rating ~ ., data = data)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-10.9418  -4.3555   0.3158   5.5425  11.5990 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 10.78708   11.58926   0.931 0.361634    \n",
       "complaints   0.61319    0.16098   3.809 0.000903 ***\n",
       "privileges  -0.07305    0.13572  -0.538 0.595594    \n",
       "learning     0.32033    0.16852   1.901 0.069925 .  \n",
       "raises       0.08173    0.22148   0.369 0.715480    \n",
       "critical     0.03838    0.14700   0.261 0.796334    \n",
       "advance     -0.21706    0.17821  -1.218 0.235577    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 7.068 on 23 degrees of freedom\n",
       "Multiple R-squared:  0.7326,\tAdjusted R-squared:  0.6628 \n",
       "F-statistic:  10.5 on 6 and 23 DF,  p-value: 1.24e-05\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = rating ~ complaints + privileges + learning + advance, \n",
       "    data = data)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-11.8976  -5.5171   0.7654   5.8086  11.5022 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 14.30347    7.73957   1.848   0.0765 .  \n",
       "complaints   0.65338    0.13051   5.006 3.67e-05 ***\n",
       "privileges  -0.07682    0.13059  -0.588   0.5616    \n",
       "learning     0.32395    0.15741   2.058   0.0502 .  \n",
       "advance     -0.17151    0.14904  -1.151   0.2607    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 6.821 on 25 degrees of freedom\n",
       "Multiple R-squared:  0.7293,\tAdjusted R-squared:  0.686 \n",
       "F-statistic: 16.84 on 4 and 25 DF,  p-value: 8.134e-07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = rating ~ complaints + learning + advance, data = data)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-12.217  -5.377   0.967   6.078  11.540 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  13.5777     7.5439   1.800   0.0835 .  \n",
       "complaints    0.6227     0.1181   5.271 1.65e-05 ***\n",
       "learning      0.3124     0.1542   2.026   0.0532 .  \n",
       "advance      -0.1870     0.1449  -1.291   0.2082    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 6.734 on 26 degrees of freedom\n",
       "Multiple R-squared:  0.7256,\tAdjusted R-squared:  0.6939 \n",
       "F-statistic: 22.92 on 3 and 26 DF,  p-value: 1.807e-07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(datasets)\n",
    "data<-attitude\n",
    "head(data)\n",
    "model.1<-lm(rating~.,data=data)\n",
    "summary(model.1)\n",
    "\n",
    "model.2<-lm(rating~complaints+privileges+learning+advance,data=data)\n",
    "summary(model.2)\n",
    "\n",
    "model.3<-lm(rating~complaints+learning+advance,data=data)\n",
    "summary(model.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Exercise 2</strong>\n",
    "Another way to measure how your model fit your data is to use the Root Mean Squared Error (RMSE), which is defined as the square root of the average of the square of all the error made by your model.\n",
    "You can find the mathematical definition of the RMSE <a href=\"https://en.wikipedia.org/wiki/Root-mean-square_deviation#Formula>on this page.</a>\n",
    "Calculate the RMSE of the prediction made by your three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.18870025349086"
      ],
      "text/latex": [
       "6.18870025349086"
      ],
      "text/markdown": [
       "6.18870025349086"
      ],
      "text/plain": [
       "[1] 6.1887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6.22631948941419"
      ],
      "text/latex": [
       "6.22631948941419"
      ],
      "text/markdown": [
       "6.22631948941419"
      ],
      "text/plain": [
       "[1] 6.226319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6.26926135998756"
      ],
      "text/latex": [
       "6.26926135998756"
      ],
      "text/markdown": [
       "6.26926135998756"
      ],
      "text/plain": [
       "[1] 6.269261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse<-function(y,y_pred){\n",
    "  RMSE <- sqrt(mean((y-y_pred)^2))\n",
    "\n",
    "  return (RMSE)\n",
    "}\n",
    "rmse(data$rating, model.1$fitted.values)\n",
    "rmse(data$rating, model.2$fitted.values)\n",
    "rmse(data$rating, model.3$fitted.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Exercise 3</strong>\n",
    "The mean absolute error (MAE) is a good alternative to the RMSE if you don't want to penalise too much the large estimation error of your model. The MAE is given by the equation\n",
    "The mathematical definition of the MAE can be found <a href=\"https://en.wikipedia.org/wiki/Mean_absolute_error>here.</a>\n",
    "Calculate the MAE of the prediction made by the 3 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.17897741841211"
      ],
      "text/latex": [
       "5.17897741841211"
      ],
      "text/markdown": [
       "5.17897741841211"
      ],
      "text/plain": [
       "[1] 5.178977"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5.27339630797658"
      ],
      "text/latex": [
       "5.27339630797658"
      ],
      "text/markdown": [
       "5.27339630797658"
      ],
      "text/plain": [
       "[1] 5.273396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5.31671822967778"
      ],
      "text/latex": [
       "5.31671822967778"
      ],
      "text/markdown": [
       "5.31671822967778"
      ],
      "text/plain": [
       "[1] 5.316718"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae<-function(y,y_pred){\n",
    "\n",
    "  MAE <- sum(abs(y-y_pred))/length(y)\n",
    "\n",
    "  return (MAE)\n",
    "}\n",
    "mae(data$rating, model.1$fitted.values)\n",
    "mae(data$rating, model.2$fitted.values)\n",
    "mae(data$rating, model.3$fitted.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Exercise 4</strong>\n",
    "Sometime some prediction error hurt your model than other. For example, if you are trying to predict the financial loss of a business over a period of time, under estimation of the loss would\n",
    "put the business at risk of bankruptcy, while overestimation of the loss will result in a conservative model. In those case, using the Root Mean Squared Logarithmic Error (RMSLE) as an error\n",
    "metric is useful since this metric penalize under estimation. The RMSLE  is given by the equation given on this <a href=\"https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError>page.</a>\n",
    "Calculate the RMSLE of the prediction made by the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.104995485543618"
      ],
      "text/latex": [
       "0.104995485543618"
      ],
      "text/markdown": [
       "0.104995485543618"
      ],
      "text/plain": [
       "[1] 0.1049955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.105628844970317"
      ],
      "text/latex": [
       "0.105628844970317"
      ],
      "text/markdown": [
       "0.105628844970317"
      ],
      "text/plain": [
       "[1] 0.1056288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.105971071158817"
      ],
      "text/latex": [
       "0.105971071158817"
      ],
      "text/markdown": [
       "0.105971071158817"
      ],
      "text/plain": [
       "[1] 0.1059711"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmlse <- function(y,y_pred) {\n",
    "\n",
    "  RMLSE<-sqrt(1/length(y)*sum((log(y_pred +1)-log(y +1))^2))\n",
    "\n",
    "  return(RMLSE)\n",
    "}\n",
    "rmlse(data$rating, model.1$fitted.values)\n",
    "rmlse(data$rating, model.2$fitted.values)\n",
    "rmlse(data$rating, model.3$fitted.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Exercise 5</strong>\n",
    "Now that we've seen some examples of error metrics which can be used in a regression context, let's see five examples of error metrics which can be used when you perform clustering analysis. But\n",
    "first, we must create a clustering model to test those metrics on. Load the iris dataset and apply the kmeans algorithm. Since the iris dataset has three distinct\n",
    "labels, use the kmeans algorithm with three centers. Also, use set the maximum number of iterations at 50 and use the \"Lloyd\" algorithm. Once it's done, take time to rearrange the labels of your\n",
    "prediction so they are compatible with the factors in the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            \n",
       "              1  2  3\n",
       "  setosa      0  0 50\n",
       "  versicolor 48  2  0\n",
       "  virginica  14 36  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            \n",
       "             setosa versicolor virginica\n",
       "  setosa         50          0         0\n",
       "  versicolor      0         48         2\n",
       "  virginica       0         14        36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster.data<-iris\n",
    "set.seed(42)\n",
    "k.means.results.1<-kmeans(cluster.data[,1:4],centers=3,iter.max = 50, algorithm = \"Lloyd\")\n",
    "table(cluster.data[,5],k.means.results.1$cluster)\n",
    "k.means.results.1$cluster<-factor(k.means.results.1$cluster)\n",
    "levels(k.means.results.1$cluster)<-list(\"setosa\"=3,\"versicolor\"=1,\"virginica\"=2)\n",
    "table(cluster.data[,5],k.means.results.1$cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
